{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Tessellate-Imaging/monk_v1/blob/master/study_roadmaps/1_getting_started_roadmap/2_elemental_features_of_monk/1)%20Feature%20-%20Experiment%20Summaries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goals\n",
    "\n",
    "### 1. Understand how you can print summaries for experiments being created\n",
    "\n",
    "### 2. You will use details from these summaries to update hyper-parameters from default state\n",
    "    - This will be dealt in later tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "\n",
    "## [Install](#0)\n",
    "\n",
    "\n",
    "## [Printing summaries before training](#1)\n",
    "\n",
    "\n",
    "## [Printing summaries after training](#2)\n",
    "\n",
    "\n",
    "## [Printing summaries after external validation](#3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "# Install Monk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using pip (Recommended)\n",
    "\n",
    "  - colab (gpu) \n",
    "      - All bakcends: `pip install -U monk-colab`\n",
    "      \n",
    "\n",
    "  - kaggle (gpu) \n",
    "      - All backends: `pip install -U monk-kaggle`\n",
    "      \n",
    "\n",
    "  - cuda 10.2\t\n",
    "      - All backends: `pip install -U monk-cuda102`\n",
    "      - Gluon bakcned: `pip install -U monk-gluon-cuda102`\n",
    "\t  - Pytorch backend: `pip install -U monk-pytorch-cuda102`\n",
    "      - Keras backend: `pip install -U monk-keras-cuda102`\n",
    "      \n",
    "\n",
    "  - cuda 10.1\t\n",
    "      - All backend: `pip install -U monk-cuda101`\n",
    "\t  - Gluon bakcned: `pip install -U monk-gluon-cuda101`\n",
    "\t  - Pytorch backend: `pip install -U monk-pytorch-cuda101`\n",
    "\t  - Keras backend: `pip install -U monk-keras-cuda101`\n",
    "      \n",
    "\n",
    "  - cuda 10.0\t\n",
    "      - All backend: `pip install -U monk-cuda100`\n",
    "\t  - Gluon bakcned: `pip install -U monk-gluon-cuda100`\n",
    "\t  - Pytorch backend: `pip install -U monk-pytorch-cuda100`\n",
    "\t  - Keras backend: `pip install -U monk-keras-cuda100`\n",
    "      \n",
    "\n",
    "  - cuda 9.2\t\n",
    "      - All backend: `pip install -U monk-cuda92`\n",
    "\t  - Gluon bakcned: `pip install -U monk-gluon-cuda92`\n",
    "\t  - Pytorch backend: `pip install -U monk-pytorch-cuda92`\n",
    "\t  - Keras backend: `pip install -U monk-keras-cuda92`\n",
    "      \n",
    "\n",
    "  - cuda 9.0\t\n",
    "      - All backend: `pip install -U monk-cuda90`\n",
    "\t  - Gluon bakcned: `pip install -U monk-gluon-cuda90`\n",
    "\t  - Pytorch backend: `pip install -U monk-pytorch-cuda90`\n",
    "\t  - Keras backend: `pip install -U monk-keras-cuda90`\n",
    "      \n",
    "\n",
    "  - cpu \t\t\n",
    "      - All backend: `pip install -U monk-cpu`\n",
    "\t  - Gluon bakcned: `pip install -U monk-gluon-cpu`\n",
    "\t  - Pytorch backend: `pip install -U monk-pytorch-cpu`\n",
    "\t  - Keras backend: `pip install -U monk-keras-cpu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Monk Manually (Not recommended)\n",
    " \n",
    "### Step 1: Clone the library\n",
    " - git clone https://github.com/Tessellate-Imaging/monk_v1.git\n",
    " \n",
    " \n",
    " \n",
    " \n",
    "### Step 2: Install requirements \n",
    " - Linux\n",
    "     - Cuda 9.0\n",
    "         - `cd monk_v1/installation/Linux && pip install -r requirements_cu90.txt`\n",
    "     - Cuda 9.2\n",
    "         - `cd monk_v1/installation/Linux && pip install -r requirements_cu92.txt`\n",
    "     - Cuda 10.0\n",
    "         - `cd monk_v1/installation/Linux && pip install -r requirements_cu100.txt`\n",
    "     - Cuda 10.1\n",
    "         - `cd monk_v1/installation/Linux && pip install -r requirements_cu101.txt`\n",
    "     - Cuda 10.2\n",
    "         - `cd monk_v1/installation/Linux && pip install -r requirements_cu102.txt`\n",
    "     - CPU (Non gpu system)\n",
    "         - `cd monk_v1/installation/Linux && pip install -r requirements_cpu.txt`\n",
    " \n",
    " \n",
    "  - Windows\n",
    "     - Cuda 9.0 (Experimental support)\n",
    "         - `cd monk_v1/installation/Windows && pip install -r requirements_cu90.txt`\n",
    "     - Cuda 9.2 (Experimental support)\n",
    "         - `cd monk_v1/installation/Windows && pip install -r requirements_cu92.txt`\n",
    "     - Cuda 10.0 (Experimental support)\n",
    "         - `cd monk_v1/installation/Windows && pip install -r requirements_cu100.txt`\n",
    "     - Cuda 10.1 (Experimental support)\n",
    "         - `cd monk_v1/installation/Windows && pip install -r requirements_cu101.txt`\n",
    "     - Cuda 10.2 (Experimental support)\n",
    "         - `cd monk_v1/installation/Windows && pip install -r requirements_cu102.txt`\n",
    "     - CPU (Non gpu system)\n",
    "         - `cd monk_v1/installation/Windows && pip install -r requirements_cpu.txt`\n",
    "         \n",
    "         \n",
    "  - Mac\n",
    "     - CPU (Non gpu system)\n",
    "         - `cd monk_v1/installation/Mac && pip install -r requirements_cpu.txt`\n",
    "         \n",
    "         \n",
    "  - Misc\n",
    "      - Colab (GPU)\n",
    "          - `cd monk_v1/installation/Misc && pip install -r requirements_colab.txt`\n",
    "      - Kaggle (GPU)\n",
    "          - `cd monk_v1/installation/Misc && pip install -r requirements_kaggle.txt`\n",
    " \n",
    " \n",
    " \n",
    "### Step 3: Add to system path (Required for every terminal or kernel run)\n",
    " - `import sys`\n",
    " - `sys.path.append(\"monk_v1/\");`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using mxnet-gluon backend \n",
    "\n",
    "# When installed using pip\n",
    "from monk.gluon_prototype import prototype\n",
    "\n",
    "\n",
    "# When installed manually (Uncomment the following)\n",
    "#import os\n",
    "#import sys\n",
    "#sys.path.append(\"monk_v1/\");\n",
    "#sys.path.append(\"monk_v1/monk/\");\n",
    "#from monk.gluon_prototype import prototype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and managing experiments\n",
    "    - Provide project name\n",
    "    - Provide experiment name\n",
    "    - For a specific data create a single project\n",
    "    - Inside each project multiple experiments can be created\n",
    "    - Every experiment can be have diferent hyper-parameters attached to it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This creates files and directories as per the following structure\n",
    "    \n",
    "    \n",
    "    workspace\n",
    "        |\n",
    "        |--------sample-project-1 (Project name can be different)\n",
    "                        |\n",
    "                        |\n",
    "                        |-----sample-experiment-1 (Experiment name can be different)\n",
    "                                    |\n",
    "                                    |-----experiment-state.json\n",
    "                                    |\n",
    "                                    |-----output\n",
    "                                            |\n",
    "                                            |------logs (All training logs and graphs saved here)\n",
    "                                            |\n",
    "                                            |------models (all trained models saved here)\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mxnet Version: 1.5.1\n",
      "\n",
      "Experiment Details\n",
      "    Project: sample-project-1\n",
      "    Experiment: sample-experiment-1\n",
      "    Dir: /home/ubuntu/Desktop/monk_pip_test/monk_v1/study_roadmaps/1_getting_started_roadmap/2_elemental_features_of_monk/workspace/sample-project-1/sample-experiment-1/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gtf = prototype(verbose=1);\n",
    "gtf.Prototype(\"sample-project-1\", \"sample-experiment-1\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick mode training\n",
    "\n",
    "    - Using Default Function\n",
    "        - dataset_path\n",
    "        - model_name\n",
    "        - num_epochs\n",
    "        \n",
    "        \n",
    "## Dataset folder structure\n",
    "\n",
    "    parent_directory\n",
    "        |\n",
    "        |\n",
    "        |------cats\n",
    "                |\n",
    "                |------img1.jpg\n",
    "                |------img2.jpg\n",
    "                |------.... (and so on)\n",
    "        |------dogs\n",
    "                |\n",
    "                |------img1.jpg\n",
    "                |------img2.jpg\n",
    "                |------.... (and so on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "import os\n",
    "if not os.path.isfile(\"datasets.zip\"):\n",
    "    os.system(\"! wget --load-cookies /tmp/cookies.txt \\\"https://docs.google.com/uc?export=download&confirm=$(wget --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1rG-U1mS8hDU7_wM56a1kc-li_zHLtbq2' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1rG-U1mS8hDU7_wM56a1kc-li_zHLtbq2\\\" -O datasets.zip && rm -rf /tmp/cookies.txt\")\n",
    "if not os.path.isdir(\"datasets\"):    \n",
    "    os.system(\"! unzip -qq datasets.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Details\n",
      "    Train path:     datasets/dataset_cats_dogs_train\n",
      "    Val path:       None\n",
      "    CSV train path: None\n",
      "    CSV val path:   None\n",
      "    Label Type:     single\n",
      "\n",
      "Dataset Params\n",
      "    Input Size:   224\n",
      "    Batch Size:   4\n",
      "    Data Shuffle: True\n",
      "    Processors:   8\n",
      "    Train-val split:   0.7\n",
      "\n",
      "Pre-Composed Train Transforms\n",
      "[{'RandomHorizontalFlip': {'p': 0.8}}, {'Normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]\n",
      "\n",
      "Pre-Composed Val Transforms\n",
      "[{'RandomHorizontalFlip': {'p': 0.8}}, {'Normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]\n",
      "\n",
      "Dataset Numbers\n",
      "    Num train images: 140\n",
      "    Num val images:   60\n",
      "    Num classes:      2\n",
      "\n",
      "Model Params\n",
      "    Model name:           resnet18_v1\n",
      "    Use Gpu:              True\n",
      "    Use pretrained:       True\n",
      "    Freeze base network:  True\n",
      "\n",
      "Model Details\n",
      "    Loading pretrained model\n",
      "    Model Loaded on device\n",
      "        Model name:                           resnet18_v1\n",
      "        Num of potentially trainable layers:  41\n",
      "        Num of actual trainable layers:       1\n",
      "\n",
      "Optimizer\n",
      "    Name:          sgd\n",
      "    Learning rate: 0.01\n",
      "    Params:        {'lr': 0.01, 'momentum': 0, 'weight_decay': 0, 'momentum_dampening_rate': 0, 'clipnorm': 0.0, 'clipvalue': 0.0}\n",
      "\n",
      "\n",
      "\n",
      "Learning rate scheduler\n",
      "    Name:   steplr\n",
      "    Params: {'step_size': 1, 'gamma': 0.98, 'last_epoch': -1}\n",
      "\n",
      "Loss\n",
      "    Name:          softmaxcrossentropy\n",
      "    Params:        {'weight': None, 'batch_axis': 0, 'axis_to_sum_over': -1, 'label_as_categories': True, 'label_smoothing': False}\n",
      "\n",
      "Training params\n",
      "    Num Epochs: 5\n",
      "\n",
      "Display params\n",
      "    Display progress:          True\n",
      "    Display progress realtime: True\n",
      "    Save Training logs:        True\n",
      "    Save Intermediate models:  True\n",
      "    Intermediate model prefix: intermediate_model_\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.virtualenvs/monk_pip_test/lib/python3.6/site-packages/monk/system/imports.py:160: UserWarning: ArgumentWarning: clipnorm and clipvalue are active only for keras in current version of Monk\n",
      "  warnings.warn(msg)\n",
      "/home/ubuntu/.virtualenvs/monk_pip_test/lib/python3.6/site-packages/monk/system/imports.py:160: UserWarning: ArgumentWarning: momentum_dampening_rate is active only for pytorch in current version of Monk\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "gtf.Default(dataset_path=\"datasets/dataset_cats_dogs_train\", \n",
    "            model_name=\"resnet18_v1\", \n",
    "            num_epochs=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "# Printing summaries before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Experiment Summary\n",
      "\n",
      "System\n",
      "    Project Name:    sample-project-1\n",
      "    Project Dir:     workspace/sample-project-1/\n",
      "    Experiment Name: sample-experiment-1\n",
      "    Experiment Dir:  workspace/sample-project-1/sample-experiment-1/\n",
      "    Library:         Mxnet\n",
      "    Origin:          ['New', 'New']\n",
      "\n",
      "Dataset\n",
      "    Status:       True\n",
      "    Dataset Type: train\n",
      "    Train path:   datasets/dataset_cats_dogs_train\n",
      "    Val path:     None\n",
      "    Test path:    False\n",
      "    CSV Train:    None\n",
      "    CSV Val:      None\n",
      "    CSV Test:     False\n",
      "\n",
      "Dataset Parameters:\n",
      "    Input Size:   224\n",
      "    Batch Size:   4\n",
      "    Shuffle:      True\n",
      "    Processors:   8\n",
      "    Num Classes:  2\n",
      "\n",
      "Dataset Transforms:\n",
      "    Train transforms: [{'RandomHorizontalFlip': {'p': 0.8}}, {'Normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]\n",
      "    Val transforms:   [{'RandomHorizontalFlip': {'p': 0.8}}, {'Normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]\n",
      "    Test transforms:  [{'Normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]\n",
      "\n",
      "Model\n",
      "    Status:\n",
      "    Model Name:                     resnet18_v1\n",
      "    Use Gpu:                        True\n",
      "    Use pretrained weights:         True\n",
      "    Base network weights freezed:   True\n",
      "    Number of trainable parameters: 1\n",
      "\n",
      "Hyper-Parameters\n",
      "    Status: True\n",
      "    Optimizer:                {'name': 'sgd', 'params': {'lr': 0.01, 'momentum': 0, 'weight_decay': 0, 'momentum_dampening_rate': 0, 'clipnorm': 0.0, 'clipvalue': 0.0}}\n",
      "    Learning Rate Scheduler:  {'name': 'steplr', 'params': {'step_size': 1, 'gamma': 0.98, 'last_epoch': -1}}\n",
      "    loss:                     {'name': 'softmaxcrossentropy', 'params': {'weight': None, 'batch_axis': 0, 'axis_to_sum_over': -1, 'label_as_categories': True, 'label_smoothing': False}}\n",
      "    Num epochs:               5\n",
      "\n",
      "\n",
      "Dataset Settings\n",
      "    Status: True\n",
      "    Display progress:          True\n",
      "    Display progress realtime: True\n",
      "    Save intermediate models:  True\n",
      "    Save training logs:        True\n",
      "    Intermediate model prefix: intermediate_model_\n",
      "\n",
      "\n",
      "Training\n",
      "    Status: False\n",
      "\n",
      "External Evaluation\n",
      "    Status: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gtf.Summary();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See above summary\n",
    "   - Training Status is False\n",
    "   - Evaluation Status is False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Start\n",
      "    Epoch 1/5\n",
      "    ----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76b608b2f0ca4669aa417e2298e414cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=35.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f58551e8f2d848169c4d27eca2b16416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "    curr_lr - 0.01\n",
      "    [Epoch 1] Train-acc: 0.643, Train-loss: 0.763 | Val-acc: 0.716667, Val-loss: 0.594, | time: 1.1 sec\n",
      "\n",
      "    Epoch 2/5\n",
      "    ----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "195f8f6fa702454aa5a1a2ddd5a42267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=35.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "455b62e82fac4fa9b497e1928b265cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "    curr_lr - 0.0098\n",
      "    [Epoch 2] Train-acc: 0.643, Train-loss: 0.872 | Val-acc: 0.883333, Val-loss: 0.265, | time: 1.1 sec\n",
      "\n",
      "    Epoch 3/5\n",
      "    ----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc0188a76afd42e6b4d088bcde2aaed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=35.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c5b5e4faa34d8fa0bc950bbf8ff331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "    curr_lr - 0.009604\n",
      "    [Epoch 3] Train-acc: 0.764, Train-loss: 0.535 | Val-acc: 0.816667, Val-loss: 0.403, | time: 1.0 sec\n",
      "\n",
      "    Epoch 4/5\n",
      "    ----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "042a8d05dd8f43eeae63ca631f03323c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=35.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ca4111c8a57484487edfc9dd75b32ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "    curr_lr - 0.009411919999999999\n",
      "    [Epoch 4] Train-acc: 0.836, Train-loss: 0.360 | Val-acc: 0.800000, Val-loss: 0.462, | time: 1.0 sec\n",
      "\n",
      "    Epoch 5/5\n",
      "    ----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1621fdd2af8f4f3e92ba0e339ef46705",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=35.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16f52fc2cec54c9a962e40e6356649f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "    curr_lr - 0.009223681599999999\n",
      "    [Epoch 5] Train-acc: 0.793, Train-loss: 0.529 | Val-acc: 0.866667, Val-loss: 0.358, | time: 1.0 sec\n",
      "\n",
      "    Training completed in: 0m 5s\n",
      "    Best val Acc:          0.883333\n",
      "\n",
      "Training End\n",
      "\n",
      "Training Outputs\n",
      "    Model Dir:   /home/ubuntu/Desktop/monk_pip_test/monk_v1/study_roadmaps/1_getting_started_roadmap/2_elemental_features_of_monk/workspace/sample-project-1/sample-experiment-1/output/models/\n",
      "    Log Dir:     /home/ubuntu/Desktop/monk_pip_test/monk_v1/study_roadmaps/1_getting_started_roadmap/2_elemental_features_of_monk/workspace/sample-project-1/sample-experiment-1/output/logs/\n",
      "    Final model: final\n",
      "    Best model:  best_model\n",
      "    Log 1 - Validation accuracy history log: val_acc_history.npy\n",
      "    Log 2 - Validation loss history log:     val_loss_history.npy\n",
      "    Log 3 - Training accuracy history log:   train_acc_history.npy\n",
      "    Log 4 - Training loss history log:       train_loss_history.npy\n",
      "    Log 5 - Training curve:                  train_loss_history.npy\n",
      "    Log 6 - Validation curve:                train_loss_history.npy\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Start Training\n",
    "gtf.Train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "# Printing summaries after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Experiment Summary\n",
      "\n",
      "System\n",
      "    Project Name:    sample-project-1\n",
      "    Project Dir:     workspace/sample-project-1/\n",
      "    Experiment Name: sample-experiment-1\n",
      "    Experiment Dir:  workspace/sample-project-1/sample-experiment-1/\n",
      "    Library:         Mxnet\n",
      "    Origin:          ['New', 'New']\n",
      "\n",
      "Dataset\n",
      "    Status:       True\n",
      "    Dataset Type: train\n",
      "    Train path:   datasets/dataset_cats_dogs_train\n",
      "    Val path:     None\n",
      "    Test path:    False\n",
      "    CSV Train:    None\n",
      "    CSV Val:      None\n",
      "    CSV Test:     False\n",
      "\n",
      "Dataset Parameters:\n",
      "    Input Size:   224\n",
      "    Batch Size:   4\n",
      "    Shuffle:      True\n",
      "    Processors:   8\n",
      "    Num Classes:  2\n",
      "\n",
      "Dataset Transforms:\n",
      "    Train transforms: [{'RandomHorizontalFlip': {'p': 0.8}}, {'Normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]\n",
      "    Val transforms:   [{'RandomHorizontalFlip': {'p': 0.8}}, {'Normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]\n",
      "    Test transforms:  [{'Normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]\n",
      "\n",
      "Model\n",
      "    Status:\n",
      "    Model Name:                     resnet18_v1\n",
      "    Use Gpu:                        True\n",
      "    Use pretrained weights:         True\n",
      "    Base network weights freezed:   True\n",
      "    Number of trainable parameters: 1\n",
      "\n",
      "Hyper-Parameters\n",
      "    Status: True\n",
      "    Optimizer:                {'name': 'sgd', 'params': {'lr': 0.01, 'momentum': 0, 'weight_decay': 0, 'momentum_dampening_rate': 0, 'clipnorm': 0.0, 'clipvalue': 0.0}}\n",
      "    Learning Rate Scheduler:  {'name': 'steplr', 'params': {'step_size': 1, 'gamma': 0.98, 'last_epoch': -1}}\n",
      "    loss:                     {'name': 'softmaxcrossentropy', 'params': {'weight': None, 'batch_axis': 0, 'axis_to_sum_over': -1, 'label_as_categories': True, 'label_smoothing': False}}\n",
      "    Num epochs:               5\n",
      "\n",
      "\n",
      "Dataset Settings\n",
      "    Status: True\n",
      "    Display progress:          True\n",
      "    Display progress realtime: True\n",
      "    Save intermediate models:  True\n",
      "    Save training logs:        True\n",
      "    Intermediate model prefix: intermediate_model_\n",
      "\n",
      "\n",
      "Training\n",
      "    Status: True\n",
      "    Model dir:                      workspace/sample-project-1/sample-experiment-1/output/models/\n",
      "    Best validation accuracy:       0.883333\n",
      "    Best validation accuracy epoch: 1\n",
      "    Training time:                  0m 5s\n",
      "    Epochs completed:               5\n",
      "    Max Gpu Usage:                  1206 Mb\n",
      "\n",
      "Training Log Files\n",
      "    Train accuracy: workspace/sample-project-1/sample-experiment-1/output/logs/train_acc_history.npy\n",
      "    Train loss:     workspace/sample-project-1/sample-experiment-1/output/logs/train_loss_history.npy\n",
      "    Val accuracy:   workspace/sample-project-1/sample-experiment-1/output/logs/val_acc_history.npy\n",
      "    Val loss:       workspace/sample-project-1/sample-experiment-1/output/logs/val_loss_history.npy\n",
      "\n",
      "External Evaluation\n",
      "    Status: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gtf.Summary();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See above summary\n",
    "   - Training Status is True\n",
    "   - Training has details now\n",
    "   - External Evaluation Status is still False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the experiment in validation mode\n",
    "    - Set flag eval_infer as True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mxnet Version: 1.5.1\n",
      "\n",
      "Model Details\n",
      "    Loading model - workspace/sample-project-1/sample-experiment-1/output/models/final-symbol.json\n",
      "    Model loaded!\n",
      "\n",
      "Experiment Details\n",
      "    Project: sample-project-1\n",
      "    Experiment: sample-experiment-1\n",
      "    Dir: /home/ubuntu/Desktop/monk_pip_test/monk_v1/study_roadmaps/1_getting_started_roadmap/2_elemental_features_of_monk/workspace/sample-project-1/sample-experiment-1/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gtf = prototype(verbose=1);\n",
    "gtf.Prototype(\"sample-project-1\", \"sample-experiment-1\", eval_infer=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Details\n",
      "    Test path:      datasets/dataset_cats_dogs_eval\n",
      "    CSV test path:  None\n",
      "\n",
      "Dataset Params\n",
      "    Input Size:  224\n",
      "    Processors:   8\n",
      "\n",
      "Pre-Composed Test Transforms\n",
      "[{'Normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]\n",
      "\n",
      "Dataset Numbers\n",
      "    Num test images: 50\n",
      "    Num classes:      2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gtf.Dataset_Params(dataset_path=\"datasets/dataset_cats_dogs_eval\");\n",
    "gtf.Dataset();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run external validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bc0b6de5ec84e05b10466dbd93c0149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Result\n",
      "        class based accuracies\n",
      "            0. cat - 100.0 %\n",
      "            1. dog - 64.0 %\n",
      "        total images:            50\n",
      "        num correct predictions: 41\n",
      "        Average accuracy (%):    82.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, class_based_accuracy = gtf.Evaluate();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "# Printing summaries after external validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Experiment Summary\n",
      "\n",
      "System\n",
      "    Project Name:    sample-project-1\n",
      "    Project Dir:     workspace/sample-project-1/\n",
      "    Experiment Name: sample-experiment-1\n",
      "    Experiment Dir:  workspace/sample-project-1/sample-experiment-1/\n",
      "    Library:         Mxnet\n",
      "    Origin:          ['New', 'New']\n",
      "\n",
      "Dataset\n",
      "    Status:       True\n",
      "    Dataset Type: train\n",
      "    Train path:   datasets/dataset_cats_dogs_train\n",
      "    Val path:     None\n",
      "    Test path:    datasets/dataset_cats_dogs_eval\n",
      "    CSV Train:    None\n",
      "    CSV Val:      None\n",
      "    CSV Test:     False\n",
      "\n",
      "Dataset Parameters:\n",
      "    Input Size:   224\n",
      "    Batch Size:   4\n",
      "    Shuffle:      True\n",
      "    Processors:   8\n",
      "    Num Classes:  2\n",
      "\n",
      "Dataset Transforms:\n",
      "    Train transforms: [{'RandomHorizontalFlip': {'p': 0.8}}, {'Normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]\n",
      "    Val transforms:   [{'RandomHorizontalFlip': {'p': 0.8}}, {'Normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]\n",
      "    Test transforms:  [{'Normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]\n",
      "\n",
      "Model\n",
      "    Status:\n",
      "    Model Name:                     resnet18_v1\n",
      "    Use Gpu:                        True\n",
      "    Use pretrained weights:         True\n",
      "    Base network weights freezed:   True\n",
      "    Number of trainable parameters: 1\n",
      "\n",
      "Hyper-Parameters\n",
      "    Status: True\n",
      "    Optimizer:                {'name': 'sgd', 'params': {'lr': 0.01, 'momentum': 0, 'weight_decay': 0, 'momentum_dampening_rate': 0, 'clipnorm': 0.0, 'clipvalue': 0.0}}\n",
      "    Learning Rate Scheduler:  {'name': 'steplr', 'params': {'step_size': 1, 'gamma': 0.98, 'last_epoch': -1}}\n",
      "    loss:                     {'name': 'softmaxcrossentropy', 'params': {'weight': None, 'batch_axis': 0, 'axis_to_sum_over': -1, 'label_as_categories': True, 'label_smoothing': False}}\n",
      "    Num epochs:               5\n",
      "\n",
      "\n",
      "Dataset Settings\n",
      "    Status: True\n",
      "    Display progress:          True\n",
      "    Display progress realtime: True\n",
      "    Save intermediate models:  True\n",
      "    Save training logs:        True\n",
      "    Intermediate model prefix: intermediate_model_\n",
      "\n",
      "\n",
      "Training\n",
      "    Status: True\n",
      "    Model dir:                      workspace/sample-project-1/sample-experiment-1/output/models/\n",
      "    Best validation accuracy:       0.883333\n",
      "    Best validation accuracy epoch: 1\n",
      "    Training time:                  0m 5s\n",
      "    Epochs completed:               5\n",
      "    Max Gpu Usage:                  1206 Mb\n",
      "\n",
      "Training Log Files\n",
      "    Train accuracy: workspace/sample-project-1/sample-experiment-1/output/logs/train_acc_history.npy\n",
      "    Train loss:     workspace/sample-project-1/sample-experiment-1/output/logs/train_loss_history.npy\n",
      "    Val accuracy:   workspace/sample-project-1/sample-experiment-1/output/logs/val_acc_history.npy\n",
      "    Val loss:       workspace/sample-project-1/sample-experiment-1/output/logs/val_loss_history.npy\n",
      "\n",
      "External Evaluation\n",
      "    Status: True\n",
      "    Evaluation Dataset path: datasets/dataset_cats_dogs_eval\n",
      "    Num Images:              50\n",
      "    Num correct predictions: 41\n",
      "    Overall Accuracy:        82.0 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gtf.Summary();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See above summary\n",
    "   - External Evaluation Status is True\n",
    "   - External Evaluation has details now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goals completed\n",
    "\n",
    "### Understand how you can print summaries for experiments being created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
