{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Tessellate-Imaging/monk_v1/blob/master/study_roadmaps/4_image_classification_zoo/Classifier%20-%20Butterfly%20Specie%20Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "\n",
    "\n",
    "## Install Monk\n",
    "\n",
    "\n",
    "## Using pretrained model for classifying scene type in images\n",
    "\n",
    "\n",
    "## Training a classifier from scratch (using default mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "# Install Monk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using pip (Recommended)\n",
    "\n",
    "  - colab (gpu) \n",
    "      - All bakcends: `pip install -U monk-colab`\n",
    "      \n",
    "\n",
    "  - kaggle (gpu) \n",
    "      - All backends: `pip install -U monk-kaggle`\n",
    "      \n",
    "\n",
    "  - cuda 10.2\t\n",
    "      - All backends: `pip install -U monk-cuda102`\n",
    "      - Gluon bakcned: `pip install -U monk-gluon-cuda102`\n",
    "\t  - Pytorch backend: `pip install -U monk-pytorch-cuda102`\n",
    "      - Keras backend: `pip install -U monk-keras-cuda102`\n",
    "      \n",
    "\n",
    "  - cuda 10.1\t\n",
    "      - All backend: `pip install -U monk-cuda101`\n",
    "\t  - Gluon bakcned: `pip install -U monk-gluon-cuda101`\n",
    "\t  - Pytorch backend: `pip install -U monk-pytorch-cuda101`\n",
    "\t  - Keras backend: `pip install -U monk-keras-cuda101`\n",
    "      \n",
    "\n",
    "  - cuda 10.0\t\n",
    "      - All backend: `pip install -U monk-cuda100`\n",
    "\t  - Gluon bakcned: `pip install -U monk-gluon-cuda100`\n",
    "\t  - Pytorch backend: `pip install -U monk-pytorch-cuda100`\n",
    "\t  - Keras backend: `pip install -U monk-keras-cuda100`\n",
    "      \n",
    "\n",
    "  - cuda 9.2\t\n",
    "      - All backend: `pip install -U monk-cuda92`\n",
    "\t  - Gluon bakcned: `pip install -U monk-gluon-cuda92`\n",
    "\t  - Pytorch backend: `pip install -U monk-pytorch-cuda92`\n",
    "\t  - Keras backend: `pip install -U monk-keras-cuda92`\n",
    "      \n",
    "\n",
    "  - cuda 9.0\t\n",
    "      - All backend: `pip install -U monk-cuda90`\n",
    "\t  - Gluon bakcned: `pip install -U monk-gluon-cuda90`\n",
    "\t  - Pytorch backend: `pip install -U monk-pytorch-cuda90`\n",
    "\t  - Keras backend: `pip install -U monk-keras-cuda90`\n",
    "      \n",
    "\n",
    "  - cpu \t\t\n",
    "      - All backend: `pip install -U monk-cpu`\n",
    "\t  - Gluon bakcned: `pip install -U monk-gluon-cpu`\n",
    "\t  - Pytorch backend: `pip install -U monk-pytorch-cpu`\n",
    "\t  - Keras backend: `pip install -U monk-keras-cpu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Monk Manually (Not recommended)\n",
    " \n",
    "### Step 1: Clone the library\n",
    " - git clone https://github.com/Tessellate-Imaging/monk_v1.git\n",
    " \n",
    " \n",
    " \n",
    " \n",
    "### Step 2: Install requirements \n",
    " - Linux\n",
    "     - Cuda 9.0\n",
    "         - `cd monk_v1/installation/Linux && pip install -r requirements_cu90.txt`\n",
    "     - Cuda 9.2\n",
    "         - `cd monk_v1/installation/Linux && pip install -r requirements_cu92.txt`\n",
    "     - Cuda 10.0\n",
    "         - `cd monk_v1/installation/Linux && pip install -r requirements_cu100.txt`\n",
    "     - Cuda 10.1\n",
    "         - `cd monk_v1/installation/Linux && pip install -r requirements_cu101.txt`\n",
    "     - Cuda 10.2\n",
    "         - `cd monk_v1/installation/Linux && pip install -r requirements_cu102.txt`\n",
    "     - CPU (Non gpu system)\n",
    "         - `cd monk_v1/installation/Linux && pip install -r requirements_cpu.txt`\n",
    " \n",
    " \n",
    "  - Windows\n",
    "     - Cuda 9.0 (Experimental support)\n",
    "         - `cd monk_v1/installation/Windows && pip install -r requirements_cu90.txt`\n",
    "     - Cuda 9.2 (Experimental support)\n",
    "         - `cd monk_v1/installation/Windows && pip install -r requirements_cu92.txt`\n",
    "     - Cuda 10.0 (Experimental support)\n",
    "         - `cd monk_v1/installation/Windows && pip install -r requirements_cu100.txt`\n",
    "     - Cuda 10.1 (Experimental support)\n",
    "         - `cd monk_v1/installation/Windows && pip install -r requirements_cu101.txt`\n",
    "     - Cuda 10.2 (Experimental support)\n",
    "         - `cd monk_v1/installation/Windows && pip install -r requirements_cu102.txt`\n",
    "     - CPU (Non gpu system)\n",
    "         - `cd monk_v1/installation/Windows && pip install -r requirements_cpu.txt`\n",
    "         \n",
    "         \n",
    "  - Mac\n",
    "     - CPU (Non gpu system)\n",
    "         - `cd monk_v1/installation/Mac && pip install -r requirements_cpu.txt`\n",
    "         \n",
    "         \n",
    "  - Misc\n",
    "      - Colab (GPU)\n",
    "          - `cd monk_v1/installation/Misc && pip install -r requirements_colab.txt`\n",
    "      - Kaggle (GPU)\n",
    "          - `cd monk_v1/installation/Misc && pip install -r requirements_kaggle.txt`\n",
    " \n",
    " \n",
    " \n",
    "### Step 3: Add to system path (Required for every terminal or kernel run)\n",
    " - `import sys`\n",
    " - `sys.path.append(\"monk_v1/\");`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Used trained classifier for demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using mxnet-gluon backend \n",
    "\n",
    "# When installed using pip\n",
    "from monk.gluon_prototype import prototype\n",
    "\n",
    "\n",
    "# When installed manually (Uncomment the following)\n",
    "#import os\n",
    "#import sys\n",
    "#sys.path.append(\"monk_v1/\");\n",
    "#sys.path.append(\"monk_v1/monk/\");\n",
    "#from monk.gluon_prototype import prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1tuJTTSJBQDlhG80JCUxuoivCq7lQSu8u' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1tuJTTSJBQDlhG80JCUxuoivCq7lQSu8u\" -O cls_coffee_trained.zip && rm -rf /tmp/cookies.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! unzip -qq cls_coffee_trained.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mGluon-Densenet161\u001b[0m/  \u001b[01;34mGluon-Densenet169\u001b[0m/  \u001b[01;34mGluon-Densenet201\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls workspace/Project-Coffee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mxnet Version: 1.5.1\n",
      "\n",
      "Model Details\n",
      "    Loading model - workspace/Project-Coffee/Gluon-Densenet201/output/models/final-symbol.json\n",
      "    Model loaded!\n",
      "\n",
      "Experiment Details\n",
      "    Project: Project-Coffee\n",
      "    Experiment: Gluon-Densenet201\n",
      "    Dir: /home/ubuntu/Desktop/coffee/workspace/Project-Coffee/Gluon-Densenet201/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load project in inference mode\n",
    "\n",
    "gtf = prototype(verbose=1);\n",
    "gtf.Prototype(\"Project-Coffee\", \"Gluon-Densenet201\", eval_infer=True);\n",
    "\n",
    "#Other trained models - uncomment \n",
    "#gtf.Prototype(\"Project-Coffee\", \"Gluon-Densenet169\", eval_infer=True);\n",
    "#gtf.Prototype(\"Project-Coffee\", \"Gluon-Densenet161\", eval_infer=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction\n",
      "    Image name:         workspace/test/1.jpg\n",
      "    Predicted class:      non_coffee\n",
      "    Predicted score:      0.5715091228485107\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_name = \"workspace/test/1.jpg\"\n",
    "predictions = gtf.Infer(img_name=img_name);\n",
    "from IPython.display import Image\n",
    "Image(filename=img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction\n",
      "    Image name:         workspace/test/2.jpg\n",
      "    Predicted class:      non_coffee\n",
      "    Predicted score:      1.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_name = \"workspace/test/2.jpg\"\n",
    "predictions = gtf.Infer(img_name=img_name);\n",
    "from IPython.display import Image\n",
    "Image(filename=img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction\n",
      "    Image name:         workspace/test/3.jpg\n",
      "    Predicted class:      coffee\n",
      "    Predicted score:      1.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCABAAEADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDH1LzUsleNzG8fzZUdQKpyzC+EV+q7I2GG47itMZaE7+QOME1F5SG0uLDO7K+aAowRiqb1McDOz5WYdxJ5jhQQGzkZ70+FfOcfN9M9qg3JNIzI2W9Hp8STbxHGxy7AHPOKpan0Maa5Lo37G1iLTXsz5ihXg+prEaeW5vWkZgc9ye1W9Rv2tY47G3YHaMuR3NVIryN1QyQr5mPvKcH8qtS5UcqoylK66EU4JfZEPvcZqSVSjKjNhVGMVYhtCz+cJA8YPPODVV3xJLkZYnp6Cknc6k2tDdluAwGFOBycHrTZomuLu3mibZjAfBxxVcxOknDAr/Dt5q+0McaxtPP5KMM5Izg1LjqfLU3azRgapY/Y9UcEHymO5CelW9JiWNJryTqo4PbJqxrFkJdPW6WQShCRuGelQ3Mwt9Ohs8bWIDNWkI6HuwxHuGTdl1kMjYct1GcZqFVGc8gBeBV27KiBRjcTxzVVIpGkULjjrWM9z0cE/c1L0b7bcIoII5PamDUEYlJoNwDct0Ipkkw3nA4PBFRW9s11cxW6HcXcZGKa2uNxi5M6Q3UcUvloqySAYLdNtUpVMzu5BkGeOahtXBZkypIGTuPepIpZIQNoUKOWHrW6R8/Twyjuaeg3kMd+ltJC0kUp2sucgVk6027VrhTwEbAwO1Recyl8Ao5IKgDFWdft3fytRgI2yKFfB6GlJ8up1Uad3ZmWZvMwhGBnqepqZSqqWXB3cD1+tVowzjGcZx15qfYisTjgdcGud3Z7PJGEdAVWLgbQQON2Mc1q6BCILq41GZSI7VDtJPUmstf9W2CTnopPetXU2GnaRbafgGWX97L6jPatLaWORVHdvsVVgfeN2EY9h1qGSZjIwfBAbGO9JPN+/wCE5Xvu61EsMhRmPzEnJJ7Vpc50riytl1dThgucHrVmyf7WZbN5WdZkyoA4Uiq54X58j1z6U60YQXCfOditng9qmWqGtHdEAj+yoynG49FA5FLG8bE4Vtx7VNri+VqkjLgQyRhgRVC3IWQYyST92skd6blA3tF0/wC1X3nSf6iAeYwY9fasvULh77V3lf5fmxhuwrUvrs6dpMVgFHmy/O5B5A7Cs+0/0gATxs3+16VSkrnJyyT1Wh//2Q==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_name = \"workspace/test/3.jpg\"\n",
    "predictions = gtf.Infer(img_name=img_name);\n",
    "from IPython.display import Image\n",
    "Image(filename=img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction\n",
      "    Image name:         workspace/test/4.jpg\n",
      "    Predicted class:      coffee\n",
      "    Predicted score:      0.8895840048789978\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_name = \"workspace/test/4.jpg\"\n",
    "predictions = gtf.Infer(img_name=img_name);\n",
    "from IPython.display import Image\n",
    "Image(filename=img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training custom classifier from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "    - Credits:http://www.patreo.dcc.ufmg.br/2017/11/12/brazilian-coffee-scenes-dataset/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget http://www.patreo.dcc.ufmg.br/wp-content/uploads/2017/11/brazilian_coffee_dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! unzip -qq brazilian_coffee_dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir dataset\n",
    "! mkdir dataset/coffee\n",
    "! mkdir dataset/non_coffee "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in range(1, 6):\n",
    "    fold_num = f;\n",
    "    f = open(\"brazilian_coffee_scenes/fold\" + str(fold_num) + \".txt\");\n",
    "    lines = f.readlines();\n",
    "    f.close();\n",
    "    for i in tqdm(range(len(lines))):\n",
    "        tmp = lines[i][:len(lines[i])-1].split(\".\");\n",
    "        label = tmp[0];\n",
    "        img_name = \".\".join(tmp[1:]) + \".jpg\";\n",
    "        #print(img_name)\n",
    "        if(label == \"coffee\"):\n",
    "            os.system(\"cp brazilian_coffee_scenes/fold\" + str(fold_num) + \"/\" + img_name + \" dataset/coffee/\");\n",
    "        else:\n",
    "            os.system(\"cp brazilian_coffee_scenes/fold\" + str(fold_num) + \"/\" + img_name + \" dataset/non_coffee/\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using mxnet-gluon backend \n",
    "from monk.gluon_prototype import prototype\n",
    "\n",
    "# For pytorch backend\n",
    "#from monk.pytorch_prototype import prototype\n",
    "\n",
    "# For Keras backend\n",
    "#from monk.keras_prototype import prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mxnet Version: 1.5.1\n",
      "\n",
      "Experiment Details\n",
      "    Project: Project-ButterFly\n",
      "    Experiment: Gluon-Sample-Experiment\n",
      "    Dir: /home/ubuntu/Desktop/butterfly/workspace/Project-ButterFly/Gluon-Sample-Experiment/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create Project and Experiment\n",
    "\n",
    "gtf = prototype(verbose=1);\n",
    "gtf.Prototype(\"Project-Coffee\", \"Gluon-Densenet161\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models List: \n",
      "    1. alexnet\n",
      "    2. darknet53\n",
      "    3. densenet121\n",
      "    4. densenet161\n",
      "    5. densenet169\n",
      "    6. densenet201\n",
      "    7. inceptionv3\n",
      "    8. mobilenet1.0\n",
      "    9. mobilenet0.75\n",
      "    10. mobilenet0.25\n",
      "    11. mobilenet0.5\n",
      "    12. resnet18_v1\n",
      "    13. resnet34_v1\n",
      "    14. resnet50_v1\n",
      "    15. resnet101_v1\n",
      "    16. resnet152_v1\n",
      "    17. resnext50_32x4d\n",
      "    18. resnext101_32x4d\n",
      "    19. resnext101_64x4d_v1\n",
      "    20. se_resnext50_32x4d\n",
      "    21. se_resnext101_32x4d\n",
      "    22. se_resnext101_64x4d\n",
      "    23. senet_154\n",
      "    24. vgg11\n",
      "    25. vgg13\n",
      "    26. vgg16\n",
      "    27. vgg19\n",
      "    28. vgg11_bn\n",
      "    29. vgg13_bn\n",
      "    30. vgg16_bn\n",
      "    31. vgg19_bn\n",
      "    32. resnet18_v2\n",
      "    33. resnet34_v2\n",
      "    34. resnet50_v2\n",
      "    35. resnet101_v2\n",
      "    36. resnet152_v2\n",
      "    37. mobilenetv2_1.0\n",
      "    38. mobilenetv2_0.75\n",
      "    39. mobilenetv2_0.5\n",
      "    40. mobilenetv2_0.25\n",
      "    41. squeezenet1.0\n",
      "    42. squeezenet1.1\n",
      "    43. mobilenetv3_large\n",
      "    44. mobilenetv3_small\n",
      "    45. resnet18_v1b\n",
      "    46. resnet34_v1b\n",
      "    47. resnet50_v1b\n",
      "    48. resnet50_v1b_gn\n",
      "    49. resnet101_v1b\n",
      "    50. resnet152_v1b\n",
      "    51. resnet50_v1c\n",
      "    52. resnet101_v1c\n",
      "    53. resnet152_v1c\n",
      "    54. resnet50_v1d\n",
      "    55. resnet101_v1d\n",
      "    56. resnet152_v1d\n",
      "    57. resnet18_v1d\n",
      "    58. resnet34_v1d\n",
      "    59. resnet50_v1d\n",
      "    60. resnet101_v1d\n",
      "    61. resnet152_v1d\n",
      "    62. resnet18_v1b_0.89\n",
      "    63. resnet50_v1d_0.86\n",
      "    64. resnet50_v1d_0.48\n",
      "    65. resnet50_v1d_0.37\n",
      "    66. resnet50_v1d_0.11\n",
      "    67. resnet101_v1d_0.76\n",
      "    68. resnet101_v1d_0.73\n",
      "    69. xception\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gtf.List_Models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Details\n",
      "    Train path:     images_small\n",
      "    Val path:       None\n",
      "    CSV train path: None\n",
      "    CSV val path:   None\n",
      "    Label Type:     single\n",
      "\n",
      "Dataset Params\n",
      "    Input Size:   224\n",
      "    Batch Size:   4\n",
      "    Data Shuffle: True\n",
      "    Processors:   8\n",
      "    Train-val split:   0.7\n",
      "\n",
      "Pre-Composed Train Transforms\n",
      "[{'RandomHorizontalFlip': {'p': 0.8}}, {'Normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]\n",
      "\n",
      "Pre-Composed Val Transforms\n",
      "[{'RandomHorizontalFlip': {'p': 0.8}}, {'Normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]\n",
      "\n",
      "Dataset Numbers\n",
      "    Num train images: 17695\n",
      "    Num val images:   7584\n",
      "    Num classes:      200\n",
      "\n",
      "Model Params\n",
      "    Model name:           densenet121\n",
      "    Use Gpu:              True\n",
      "    Use pretrained:       True\n",
      "    Freeze base network:  False\n",
      "\n",
      "Model Details\n",
      "    Loading pretrained model\n",
      "Downloading /home/ubuntu/.mxnet/models/densenet121-f27dbf2d.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/densenet121-f27dbf2d.zip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29622/29622 [00:01<00:00, 29026.12KB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Model Loaded on device\n",
      "        Model name:                           densenet121\n",
      "        Num of potentially trainable layers:  242\n",
      "        Num of actual trainable layers:       242\n",
      "\n",
      "Optimizer\n",
      "    Name:          sgd\n",
      "    Learning rate: 0.01\n",
      "    Params:        {'lr': 0.01, 'momentum': 0, 'weight_decay': 0.0001, 'momentum_dampening_rate': 0, 'clipnorm': 0.0, 'clipvalue': 0.0}\n",
      "\n",
      "\n",
      "\n",
      "Learning rate scheduler\n",
      "    Name:   steplr\n",
      "    Params: {'step_size': 1, 'gamma': 0.98, 'last_epoch': -1}\n",
      "\n",
      "Loss\n",
      "    Name:          softmaxcrossentropy\n",
      "    Params:        {'weight': None, 'batch_axis': 0, 'axis_to_sum_over': -1, 'label_as_categories': True, 'label_smoothing': False}\n",
      "\n",
      "Training params\n",
      "    Num Epochs: 2\n",
      "\n",
      "Display params\n",
      "    Display progress:          True\n",
      "    Display progress realtime: True\n",
      "    Save Training logs:        True\n",
      "    Save Intermediate models:  True\n",
      "    Intermediate model prefix: intermediate_model_\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.virtualenvs/butterfly/lib/python3.6/site-packages/monk/system/imports.py:160: UserWarning: ArgumentWarning: clipnorm and clipvalue are active only for keras in current version of Monk\n",
      "  warnings.warn(msg)\n",
      "/home/ubuntu/.virtualenvs/butterfly/lib/python3.6/site-packages/monk/system/imports.py:160: UserWarning: ArgumentWarning: momentum_dampening_rate is active only for pytorch in current version of Monk\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "gtf.Default(dataset_path=\"dataset\",\n",
    "            model_name=\"densenet161\", \n",
    "            freeze_base_network=False,\n",
    "            num_epochs=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to change hyper parameters and models \n",
    "  - Docs - https://github.com/Tessellate-Imaging/monk_v1#4\n",
    "  - Examples - https://github.com/Tessellate-Imaging/monk_v1/tree/master/study_roadmaps/1_getting_started_roadmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update batch size\n",
    "gtf.update_batch_size(16);\n",
    "gtf.update_save_intermediate_models(False);\n",
    "\n",
    "# Reload after updates\n",
    "gtf.Reload();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Start\n",
      "    Epoch 1/2\n",
      "    ----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1be3393b48594332bae5e2a01ae717e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1106.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Start Training\n",
    "gtf.Train();\n",
    "\n",
    "#Read the training summary generated once you run the cell and training is completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference (Post training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using mxnet-gluon backend\n",
    "# When installed using pip\n",
    "from monk.gluon_prototype import prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf = prototype(verbose=1);\n",
    "gtf.Prototype(\"Project-Coffee\", \"Gluon-Densenet161\", eval_infer=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = \"dataset/non_coffee/arceburgo.T1728.B1792.L5056.R5120.jpg\"\n",
    "predictions = gtf.Infer(img_name=img_name);\n",
    "from IPython.display import Image\n",
    "Image(filename=img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
