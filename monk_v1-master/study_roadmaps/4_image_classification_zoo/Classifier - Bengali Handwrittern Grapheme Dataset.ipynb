{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Tessellate-Imaging/monk_v1/blob/master/study_roadmaps/4_image_classification_zoo/Classifier%20-%20Bengali%20Handwrittern%20Grapheme%20Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "\n",
    "\n",
    "## Install Monk\n",
    "\n",
    "\n",
    "## Using pretrained model for benhali handwritten grapheme classification\n",
    "\n",
    "\n",
    "## Training a classifier from scratch (using default params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using pip (Recommended)\n",
    "\n",
    "  - colab (gpu) \n",
    "      - All bakcends: `pip install -U monk-colab`\n",
    "      \n",
    "\n",
    "  - kaggle (gpu) \n",
    "      - All backends: `pip install -U monk-kaggle`\n",
    "      \n",
    "\n",
    "  - cuda 10.2\t\n",
    "      - All backends: `pip install -U monk-cuda102`\n",
    "      - Gluon bakcned: `pip install -U monk-gluon-cuda102`\n",
    "\t  - Pytorch backend: `pip install -U monk-pytorch-cuda102`\n",
    "      - Keras backend: `pip install -U monk-keras-cuda102`\n",
    "      \n",
    "\n",
    "  - cuda 10.1\t\n",
    "      - All backend: `pip install -U monk-cuda101`\n",
    "\t  - Gluon bakcned: `pip install -U monk-gluon-cuda101`\n",
    "\t  - Pytorch backend: `pip install -U monk-pytorch-cuda101`\n",
    "\t  - Keras backend: `pip install -U monk-keras-cuda101`\n",
    "      \n",
    "\n",
    "  - cuda 10.0\t\n",
    "      - All backend: `pip install -U monk-cuda100`\n",
    "\t  - Gluon bakcned: `pip install -U monk-gluon-cuda100`\n",
    "\t  - Pytorch backend: `pip install -U monk-pytorch-cuda100`\n",
    "\t  - Keras backend: `pip install -U monk-keras-cuda100`\n",
    "      \n",
    "\n",
    "  - cuda 9.2\t\n",
    "      - All backend: `pip install -U monk-cuda92`\n",
    "\t  - Gluon bakcned: `pip install -U monk-gluon-cuda92`\n",
    "\t  - Pytorch backend: `pip install -U monk-pytorch-cuda92`\n",
    "\t  - Keras backend: `pip install -U monk-keras-cuda92`\n",
    "      \n",
    "\n",
    "  - cuda 9.0\t\n",
    "      - All backend: `pip install -U monk-cuda90`\n",
    "\t  - Gluon bakcned: `pip install -U monk-gluon-cuda90`\n",
    "\t  - Pytorch backend: `pip install -U monk-pytorch-cuda90`\n",
    "\t  - Keras backend: `pip install -U monk-keras-cuda90`\n",
    "      \n",
    "\n",
    "  - cpu \t\t\n",
    "      - All backend: `pip install -U monk-cpu`\n",
    "\t  - Gluon bakcned: `pip install -U monk-gluon-cpu`\n",
    "\t  - Pytorch backend: `pip install -U monk-pytorch-cpu`\n",
    "\t  - Keras backend: `pip install -U monk-keras-cpu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Monk Manually (Not recommended)\n",
    " \n",
    "### Step 1: Clone the library\n",
    " - git clone https://github.com/Tessellate-Imaging/monk_v1.git\n",
    " \n",
    " \n",
    " \n",
    " \n",
    "### Step 2: Install requirements \n",
    " - Linux\n",
    "     - Cuda 9.0\n",
    "         - `cd monk_v1/installation/Linux && pip install -r requirements_cu90.txt`\n",
    "     - Cuda 9.2\n",
    "         - `cd monk_v1/installation/Linux && pip install -r requirements_cu92.txt`\n",
    "     - Cuda 10.0\n",
    "         - `cd monk_v1/installation/Linux && pip install -r requirements_cu100.txt`\n",
    "     - Cuda 10.1\n",
    "         - `cd monk_v1/installation/Linux && pip install -r requirements_cu101.txt`\n",
    "     - Cuda 10.2\n",
    "         - `cd monk_v1/installation/Linux && pip install -r requirements_cu102.txt`\n",
    "     - CPU (Non gpu system)\n",
    "         - `cd monk_v1/installation/Linux && pip install -r requirements_cpu.txt`\n",
    " \n",
    " \n",
    "  - Windows\n",
    "     - Cuda 9.0 (Experimental support)\n",
    "         - `cd monk_v1/installation/Windows && pip install -r requirements_cu90.txt`\n",
    "     - Cuda 9.2 (Experimental support)\n",
    "         - `cd monk_v1/installation/Windows && pip install -r requirements_cu92.txt`\n",
    "     - Cuda 10.0 (Experimental support)\n",
    "         - `cd monk_v1/installation/Windows && pip install -r requirements_cu100.txt`\n",
    "     - Cuda 10.1 (Experimental support)\n",
    "         - `cd monk_v1/installation/Windows && pip install -r requirements_cu101.txt`\n",
    "     - Cuda 10.2 (Experimental support)\n",
    "         - `cd monk_v1/installation/Windows && pip install -r requirements_cu102.txt`\n",
    "     - CPU (Non gpu system)\n",
    "         - `cd monk_v1/installation/Windows && pip install -r requirements_cpu.txt`\n",
    "         \n",
    "         \n",
    "  - Mac\n",
    "     - CPU (Non gpu system)\n",
    "         - `cd monk_v1/installation/Mac && pip install -r requirements_cpu.txt`\n",
    "         \n",
    "         \n",
    "  - Misc\n",
    "      - Colab (GPU)\n",
    "          - `cd monk_v1/installation/Misc && pip install -r requirements_colab.txt`\n",
    "      - Kaggle (GPU)\n",
    "          - `cd monk_v1/installation/Misc && pip install -r requirements_kaggle.txt`\n",
    " \n",
    " \n",
    " \n",
    "### Step 3: Add to system path (Required for every terminal or kernel run)\n",
    " - `import sys`\n",
    " - `sys.path.append(\"monk_v1/\");`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Used trained classifier for demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using mxnet-gluon backend \n",
    "\n",
    "# When installed using pip\n",
    "from monk.gluon_prototype import prototype\n",
    "\n",
    "\n",
    "# When installed manually (Uncomment the following)\n",
    "#import os\n",
    "#import sys\n",
    "#sys.path.append(\"monk_v1/\");\n",
    "#sys.path.append(\"monk_v1/monk/\");\n",
    "#from monk.keras_prototype import prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1bzqPBwFVMOZ-3p2sS2f4MHDM1kOwpbiy' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1bzqPBwFVMOZ-3p2sS2f4MHDM1kOwpbiy\" -O cls_bengali_grapheme_trained.zip && rm -rf /tmp/cookies.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! unzip -qq cls_bengali_grapheme_trained.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mGluon-resnet18\u001b[0m/  \u001b[01;34mGluon-resnet34\u001b[0m/  \u001b[01;34mGluon-resnet50\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls workspace/Project-Bengali-Character-Consonent/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mxnet Version: 1.5.1\n",
      "\n",
      "Model Details\n",
      "    Loading model - workspace/Project-Bengali-Character-Grapheme/Gluon-resnet50/output/models/final-symbol.json\n",
      "    Model loaded!\n",
      "\n",
      "Experiment Details\n",
      "    Project: Project-Bengali-Character-Grapheme\n",
      "    Experiment: Gluon-resnet50\n",
      "    Dir: /home/ubuntu/Desktop/bengali/workspace/Project-Bengali-Character-Grapheme/Gluon-resnet50/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load project in inference mode\n",
    "\n",
    "gtf1 = prototype(verbose=1);\n",
    "gtf1.Prototype(\"Project-Bengali-Character-Grapheme\", \"Gluon-resnet50\", eval_infer=True);\n",
    "\n",
    "#Other trained models - uncomment \n",
    "#gtf1.Prototype(\"Project-Bengali-Character-Grapheme\", \"Gluon-resnet34\", eval_infer=True);\n",
    "#gtf1.Prototype(\"Project-Bengali-Character-Grapheme\", \"Gluon-resnet18\", eval_infer=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mxnet Version: 1.5.1\n",
      "\n",
      "Model Details\n",
      "    Loading model - workspace/Project-Bengali-Character-Vowel/Gluon-resnet50/output/models/final-symbol.json\n",
      "    Model loaded!\n",
      "\n",
      "Experiment Details\n",
      "    Project: Project-Bengali-Character-Vowel\n",
      "    Experiment: Gluon-resnet50\n",
      "    Dir: /home/ubuntu/Desktop/bengali/workspace/Project-Bengali-Character-Vowel/Gluon-resnet50/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load project in inference mode\n",
    "\n",
    "gtf2 = prototype(verbose=1);\n",
    "gtf2.Prototype(\"Project-Bengali-Character-Vowel\", \"Gluon-resnet50\", eval_infer=True);\n",
    "\n",
    "#Other trained models - uncomment \n",
    "#gtf2.Prototype(\"Project-Bengali-Character-Vowel\", \"Gluon-resnet34\", eval_infer=True);\n",
    "#gtf2.Prototype(\"Project-Bengali-Character-Vowel\", \"Gluon-resnet18\", eval_infer=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mxnet Version: 1.5.1\n",
      "\n",
      "Model Details\n",
      "    Loading model - workspace/Project-Bengali-Character-Consonent/Gluon-resnet50/output/models/final-symbol.json\n",
      "    Model loaded!\n",
      "\n",
      "Experiment Details\n",
      "    Project: Project-Bengali-Character-Consonent\n",
      "    Experiment: Gluon-resnet50\n",
      "    Dir: /home/ubuntu/Desktop/bengali/workspace/Project-Bengali-Character-Consonent/Gluon-resnet50/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load project in inference mode\n",
    "\n",
    "gtf3 = prototype(verbose=1);\n",
    "gtf3.Prototype(\"Project-Bengali-Character-Consonent\", \"Gluon-resnet50\", eval_infer=True);\n",
    "\n",
    "#Other trained models - uncomment \n",
    "#gtf3.Prototype(\"Project-Bengali-Character-Consonent\", \"Gluon-resnet34\", eval_infer=True);\n",
    "#gtf3.Prototype(\"Project-Bengali-Character-Consonent\", \"Gluon-resnet18\", eval_infer=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "img_list = os.listdir(\"workspace/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Test_2.jpg', 'Test_0.jpg', 'Test_1.jpg']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction\n",
      "    Image name:         workspace/test/Test_0.jpg\n",
      "    Predicted class:      grapheme_root_3\n",
      "    Predicted score:      0.9314128756523132\n",
      "\n",
      "Prediction\n",
      "    Image name:         workspace/test/Test_0.jpg\n",
      "    Predicted class:      vowel_diacritic_0\n",
      "    Predicted score:      0.9973722696304321\n",
      "\n",
      "Prediction\n",
      "    Image name:         workspace/test/Test_0.jpg\n",
      "    Predicted class:      consonant_diacritic_0\n",
      "    Predicted score:      0.9780309796333313\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_name = \"workspace/test/Test_0.jpg\"\n",
    "predictions1 = gtf1.Infer(img_name=img_name);\n",
    "predictions2 = gtf2.Infer(img_name=img_name);\n",
    "predictions3 = gtf3.Infer(img_name=img_name);\n",
    "from IPython.display import Image\n",
    "Image(filename=img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction\n",
      "    Image name:         workspace/test/Test_1.jpg\n",
      "    Predicted class:      grapheme_root_93\n",
      "    Predicted score:      0.9997119307518005\n",
      "\n",
      "Prediction\n",
      "    Image name:         workspace/test/Test_1.jpg\n",
      "    Predicted class:      vowel_diacritic_2\n",
      "    Predicted score:      0.9997062683105469\n",
      "\n",
      "Prediction\n",
      "    Image name:         workspace/test/Test_1.jpg\n",
      "    Predicted class:      consonant_diacritic_0\n",
      "    Predicted score:      0.9973165392875671\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_name = \"workspace/test/Test_1.jpg\"\n",
    "predictions1 = gtf1.Infer(img_name=img_name);\n",
    "predictions2 = gtf2.Infer(img_name=img_name);\n",
    "predictions3 = gtf3.Infer(img_name=img_name);\n",
    "from IPython.display import Image\n",
    "Image(filename=img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction\n",
      "    Image name:         workspace/test/Test_2.jpg\n",
      "    Predicted class:      grapheme_root_19\n",
      "    Predicted score:      0.7086917161941528\n",
      "\n",
      "Prediction\n",
      "    Image name:         workspace/test/Test_2.jpg\n",
      "    Predicted class:      vowel_diacritic_0\n",
      "    Predicted score:      0.999880850315094\n",
      "\n",
      "Prediction\n",
      "    Image name:         workspace/test/Test_2.jpg\n",
      "    Predicted class:      consonant_diacritic_0\n",
      "    Predicted score:      0.9999752044677734\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAIBAQEBAQIBAQECAgICAgQDAgICAgUEBAMEBgUGBgYFBgYGBwkIBgcJBwYGCAsICQoKCgoKBggLDAsKDAkKCgr/wAALCACJAOwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/AP32MYPUfrSNBG/3owfrTRaW+3YYE2+mOKU2sBYN5SggYBxQLaIdFH5UohVeg/Kl2rtILYB7mmtHCvzM4prQWZba6oSR3x0oNrZZy0aevIFKLO0X/lkgx/sCneXAFOCMDrgVGfsuSCVyOuT0pFktSQVdT82Bg96d9qtgobzkwenNZmr+P/Avh29h07xB4z0mwuLj/UQXmoRxPLzj5VYgtzxxWtFfWTsEW5Riw4AbOakYHPAp44FBGRiq/wBnDD5gab9mjGQLcYzhhjgioxYIrDbbRLjJUKnAJ+9+dSojRjY0I9iATn60FXOMxgf3cDjHoajFoo3BLWNfMOSQnf1NNewjcGM2iEEjgr0x6UxtLhmJE1iGVydwZevGOfqMCok0RI3LJZLgk9hx0IA/HP0ouNGsZJSZ7AyY4U+XnA9PzyfxrXwPQUYHoKMD0owPSikb7tQX6q9qwkHGPSvmf9pz/gqV+xh+yJ8VtI+CXx6+LUekeJNaVJLTTltZJmEbvtV2ZFIVc+tdH41/4KLfsRfDnVo9A8cftKeE9Ku5bNLpILzVERzEy7lb6EV8/wDxM/4ONP8Agl54JTULPRvjLc+IbuyJRrbRNJll3EejY2kH618xfFP/AIOxvhlY2Yk+B/7LGvaowTMtz4r1WGxjTJIBG0SFvXHH1r5Tv/8Ag4f/AOCzXxl+Lui23watNCWS91pZNM8C+Gvh++o/2lAGyLeRnVp23gFDJDJERklSpwR9I+Jv+CjH/Bxz8WZhofw3/YVfwwLqZJbOW4+DurRm2OACj3N7eiEKW9Ixgf3fvUw6V/wdU/E60j1OPTW8OvEpgmt7PUND09WdPlMuyaaVm3cnIYAkkgYNeZ/tGeFf+Dmn4H/BTxT8YP2ifj8ujeE9AsDc394nizTPNVCwQIot1ySS/QdzXwNa+E/2rf2jfhhq37T/AIm1Pxzrmh+ErlLa88V3GqTGKxcv1R3bs5ydvQ1+9P8Awb1/tm+L/wBqf9lS68CfF3xKdX8a/DTUk0u+u5H/AH1zYuubaaTuzlQwJPoK/RMDAxS0UUUUUUUUUVDLHMXJjjyPXeRU1FFFFI33ahvRI1qwWPc2OBnBr4M/4KL/APBGDwr+2p+0X4R/ak0XXJNP8SaCkdrqUF1d7La7tkcOAESCRt+RjO5RivCPjz/wb1x/tJ+NvGHxV+NHiPU7W3WBovDWg+GmTzGVVwhZ3HQHHAwSPSvzAf4JfszfsW/tDap+yj+2t4R1jSjO0cMniqDTWH2ZGw0dyIzgyRlThsdGBFful+zT/wAEnf8Agmwml2fxk+GHwx8M+K9G1vS7NtHu5IUu7SW2VDsdQ2QWLMWYnnjaehr6j8I/Bf4U+Brm1/4RX4Z6JpRstyWUun6ZFEYkxtCqwAIGGbgV14DphAu5fQjpTpgEhdhCOFPA6mvyy/4Op/ip/wAIp+wd4Y+FMk1zBe+M/HFt5SxE7GjtI3mkR2B+6QQcHqR7V2H7M37HPhfxV/wb+2HwD0zThpS+JvhVdXt5qc9sryi7lV5vOZOjElVH0wa+Qf8Ag09+LXiG6/aH8f8AhOa3kNv4l8A2WrXikDbbyW0yQghsZ5Ex4J7j0r95GBPApaKKKKKKKKKKTI70tFFFFFFI/SoLqOWW2eKFsOy4Un1r4S/4K/8A/BGDw5/wUo8P6T408M+Lo/C3xD8LQTLpGsTWgmtb2GQfNa3C/e2EhSGHII+tfmr8Efi1/wAFcf8Ag361KPRvjH8KDrvwkudU36jpwvvtWkxyP977Hdgb7RipH302M4GQa/Uj9hH/AILffsUft36xa+AvDfie58IeMGto5k8MeMPLtnu8j5haShylzgnoMNjnbX2bFd2sgDLKPmGV3DGfzqRypUnGeOK/LH/g6q+Cuq+PP2G/D3xqsUeY/DnxZHdXloi8Pb3S/Z5HPoEDBs+1WP8Agl/+3VafE7/ghZ4l8TeMSi6j8LvC+p6Jq8IfLNBBbGSCUjqA0T4HrsNeAf8ABo/4Hu4PG3xY8Y6xbS+bpvhvQtKs5i3yxrOZpJI/c5t4uvpX7l0UUUUUUUUUUVHkEnII5qSiiiiiikf7tMqvNe25Vog+SRjGOtYHjLwd4c8X6BN4f8SeH7HUbOWMLcWV7brLHIvYFWBBHWvzN/b4/wCDaf4C/G6G78f/ALIepL8NfFG43CaXC5bSrmYZbGwfNbHJ4eLGP7prw/8A4JXf8FZ/20v2Zf2u7P8A4Jzft+61ceIbU6+NCs/EGs3Wb7RZ8YjBuH5urd8Da0mX5GDjgfuOD8nt9a8t/bG/Zl0P9rj9mjxp+zp4iufItfF2gT6e9wFBMJdSA/PocHj0r+YnWfjd+1D/AMElPFnxx/Yw8d+DBfQ+K/DNz4e8V6TJIypPFIrpa6vbkf8ATN8j2LKeRX6U/wDBp58Uvhp4s8P/ABst/D+vQx6zPquhF9NlkAuDbxQXAEgjzkpulI3DoepGRX7N/wBsWm0sGJ2kBsDpVlWDAMOhpaKKKKKKKKKqTwytKWjkKjPRRVuiiiiiikcZWoLs7bZzkcLxlsD86/ID/gpX/wAF7f2uvgp+1t4l/Y6/ZE/ZYj1TWPDN3FDLr+qZmS6ZkDkIikBV56lu1YXxI/4LV/8ABT/wt8E/DN3D8APB8fiS+gI8Q6hLdYSxl3fKjQs3p3Ga+OPir/wVs/4KseGPFt7rWt/tX3ulXusSA2WlaNBFJbIT0jiTaST2x1rxlp/2ifiP+054W/a1/bs8U6yBbaxZ6lq82sWQ02/v7S1lU4topI1E5Uc84OOhNf1SfCb4x/Dr43/DjRfil8MvEkOqaHr9jHd6XewHIkjccZ9CDkEdiCK6nqCPavz9/wCC9n7E/wCzN8ZP2JPiJ+0F8Rvg7Z6l408GeC7m50PxLbTNBeWpjUuimRP9ZGCMlWB6kDGTX45/sIf8Etv2of2u9I1344fsXeMbHR9V8L3KafPJF4gfTZnlKCZF3RAkrkpyRglcdq+nPhN/wWt/4Kf/APBMv4t6J8Cv+CnXw6k1zRpDG13calDGNUSyLMpu4bmFit0R1KyDlUx8pOa/cP4H/H74T/tF/C3RfjH8G/FsGt+HtdskuNO1C2BCupH3WB5RgeCpwQRXZ0UUUUUUUUVXuJikhUED6mrFFFFFFFIwJGBUVzbG5haBuAwwea+F/wBr/wD4If8AgH9pb406n8dfA3xo1TwJq+tSJLrcdpo8N7DezIABKVkZdrEAZ7cdK4Hwp/wbefAe5vZPEfx6/aK8f+K74yiQmwv102AY6ARxZ/nX0F8Av+CS/wCwZ+z14ij8ZeCfglZ32uIQ8eta8TfXII7h5c7T9AK8R/4OC/2bvgF8Xv2L7nxD4++K3hLwL4q8Isb/AMIalr+qx2i3Eig7rX+84kXK7VUnJ4r4x/4No/8Agqx8NvAGp65+xd8cPixpGgeHnthq/ga/8R6nHaxLOzYns1eQgAOMSKrMDlSFB3V+6tp4i0a/OLK/il4B/dyBuD0PBrwT/gqTpyeIv+CdXxr0GOEsbr4b6qgHHeB8dfxNfmd/wagfFb4c3F18V/AdnqQOova6feTlnwvlorqep6gnk19Rf8FadQ/4Jjftq/C3Vv2fPiR+1D4G0Xx5okbz+H9Rn1SIXGnXag4RmOfkPQr0wa+CP+Dfn/gpFrP7I/7TSf8ABPv4r+MF1vwn4p1qW28OahaXKzWenagCctFKTgQy9Sq4we1f0GxXCmJSV6qOlSjkZooooooooqrcmHzj5ku0+mM1aoooooooopH+7UF04jtpJGOAqEn24r8Rv+CmH/Byz8Svhn8bde/Zp/Yq8EWQuPDd1Jaa74t8QQbxbyr94wxng7T3bINcv8Bf+CW37Rv/AAWM0vTP2pf2lfjlqsOm69IlxF4g1XQ4xeRRr8rQWsJcxorHO07SuOcHpX5wfF79ly813/goVqX7JfwBhtPHtqvj8+F/Cup6naRWr375CO8jjakTRsWBfCg+WSAM4r9B9D/4IHf8FkP2Mpbn4k/smfHDQY7mCSJ10XwN45vrW5u9vzDfFeQR2kwB6o7EelQ+N/8Agsj/AMFEPC3gDxd+x7/wUY+AkcNvr3hm50m91C5tH0jVlV0ZDOu79xc9eChVT2r8sf2e/EvxM+GPxRsdO+FfiXV9NvPEsy6NILfV/sZuoZJNqK0ikAds5OK+z/hl/wAEePil8Rfjcvw/+IvwC+L+k3l1qcYv/E1rp1rdWUYk/wCW7SzMTInfKnkV+kH7Mn/Brh8Ifgv8cPDvxb8c/tDa14ks/DWqRajYaVHp0dqJJkIZSzx/MBkdB1r9X269O1TJnYM+lLRRRRRRRVWcYkO5c1aoooooooopHOFqKQho2HYgg1/P3/wWQ/4JY+NPh/8Atza78evhf+z/AK54h8KeMZI9SvU0a1N1HLeDBljlVSDEGx24IqP4m/8ABQz/AILFWvhjwd+z14M020+G8fieOHTfBmkaf4cjs7yZdhWO3jdiwzsGORnvX0D/AMEK/wDgil8Y/gJ8Srj9rX9tjSoYfFMN1NN4X0Q3onkglnJM95cNghpjk49Mmv1yvJCLdgiq/wApIRlHzfjXyj481nQ/2gPjlrf7If7YH7Kx1vwvc6ZLqGla/e6THPpn2ZVwyCY5eObqeMEetfzl/wDBQH4T/BfR/wBo3xlo37O3g/UtB8IaR4mCeGLTULoyOhRwGlQkbjEW+7nPAxX9T/7GOl+J4/2Uvh2fHetR6lqv/CH2BvLqJNiSEwIVO3124H4V62sfAIx+FJ5H+1+lSAYGKKKKKKKKKpXMo84hmAxx8xFXaKKKKKKKKRhlTUTbSpB546GqUukC4XEgQgk7twzkVgaz8G/APiTWLDX/ABF4T068utJuBcaZNPZI72soGN0bEZU49K8o/bM/4KKfspfsDeH4NW+P3jpra+vgf7L8N6RAbrULwjrshBG0f7blV96/Or4j/wDByT+0H8YvEuoeFv2If2XrFLLS7SW41DVvFsst1LDAoz5syWxWO0H/AF0ds9q4DwZ/wdgX+j+ObLw18fP2ebe58MrbJDrus6BOxKytw7pGxOU9s818qf8ABUr42fC747/8FBrnUvhdYwnwp4i0nQJfDTRWJi3RXDDchXHBznPfNf0xfCbw/HoHws8NaJAgjFp4fs4Au3BUJAi4/SumAwMUUUUUUUUUUVUuIk80lwjE85Y9PardFFFFFFFFIwyCBTDFntijyccs3Argv2j/AI36F+z38C/Fnxq8RgC08M6HPfzbgSDsQ7Qcc8tgfjX8+n7IfgDxz/wW4/b2u/id+078ctK0Kxu5RINIa/jS6urNWzHY2UTHIj2/eI9T61++Hwn/AGX/AIA/ATwDZ/DT4UfCfw34c0WCMRmx0vR4IUckYZnCgbi3cnJJNfDH/BZL/ghV+z1+0R8HfEnx2+DnhWHwv4/0bTnvSdFhEFtqqRAu0UsO5YixAOHGGHvX4Y/sleG/Hnxy/bY+EvgPQZEubvUvH2nW8dveXGTEtvICyMQc4ARgB04r+w8YjRVRQABwPSnA5GaKKKKKKKKKKq3QTzjlgPqatUUUUUUUUUUUjglCAe1cr8UPhd4R+L3gHV/hr4+01b3RtbsntdStG4EsTDBBr8U/22P+DeP46/B/xta/Fb9g7WZ9cs7K/D6Zo0l6LTUdJbO5Whn6OAfXnFfS/wDwS/8AHv8AwXjufiRonhH9r34X6FJ8ObaaSHWfEGuSxRa0AowhUxPiXkDnaCeua/TC80ay1Kwk0+7XfDLGUdHAYMpGCCDkH8q+R/g3/wAENP2CfgV+1k37Y/gbwhrQ8TR6lPf6bp91qivpum3Ev3pLeARjyzkkjLHG419jrgrjHApelFFFFFFFFFFULyUJcMGZx6c1foooooooooooIyMUww5GC55qp/YkO4s0hOeg6CpI9MjjBXdxjH0qdYQoADZx3NAiI705RtGKWiiiiiiiiiiqd7uM/DPwOxA/nVyiiiiiiiiiiiiiiiiiiiiiiiiiiiisjUzfi9cWljBKvGWuGYEHHQYU8f1zWvRRRRRRRRRRRRRRRRRRRRRRRRRRRRWdqUsUd0Q/lA4H+sXk1o0UUUUUUUUUUUUUUUUUUUUUUUUUUUVn3wb7S2YEfpgscVb82T0/SgSSE4P8qfl/f8qAXJ5FOoooo59P1pPm9BS0UUUUUUUUUUUUUUUUUVRvkka4JjmlUY5CAY/WrVKn3hT6KKKKKKKKKKKKKKKKKKKKKKKKKKrT/wCtNf/Z\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_name = \"workspace/test/Test_2.jpg\"\n",
    "predictions1 = gtf1.Infer(img_name=img_name);\n",
    "predictions2 = gtf2.Infer(img_name=img_name);\n",
    "predictions3 = gtf3.Infer(img_name=img_name);\n",
    "from IPython.display import Image\n",
    "Image(filename=img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Details\n",
    "  - Credits: https://www.kaggle.com/c/bengaliai-cv19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! kaggle competitions download -c bengaliai-cv19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! unzip -qq bengaliai-cv19.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install fastparquet pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir dataset\n",
    "! mkdir dataset/train\n",
    "! mkdir dataset/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_list = pd.read_parquet(\"train_image_data_0.parquet\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_list.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(len(parquet_list))):\n",
    "    img_id = parquet_list[\"image_id\"][i]\n",
    "    row = np.array(parquet_list.iloc[i][1:])\n",
    "    row = np.reshape(row, (137, 236))\n",
    "    img = np.array(row);\n",
    "    img = img.astype(np.uint8)\n",
    "    #print(img_id, img.shape)\n",
    "    cv2.imwrite(\"dataset/train/\" + img_id + '.jpg', img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_list = pd.read_parquet(\"train_image_data_1.parquet\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(len(parquet_list))):\n",
    "    img_id = parquet_list[\"image_id\"][i]\n",
    "    row = np.array(parquet_list.iloc[i][1:])\n",
    "    row = np.reshape(row, (137, 236))\n",
    "    img = np.array(row);\n",
    "    img = img.astype(np.uint8)\n",
    "    cv2.imwrite(\"dataset/train/\" + img_id + '.jpg', img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_list = pd.read_parquet(\"train_image_data_2.parquet\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(len(parquet_list))):\n",
    "    img_id = parquet_list[\"image_id\"][i]\n",
    "    row = np.array(parquet_list.iloc[i][1:])\n",
    "    row = np.reshape(row, (137, 236))\n",
    "    img = np.array(row);\n",
    "    img = img.astype(np.uint8)\n",
    "    #print(img_id, img.shape)\n",
    "    cv2.imwrite(\"dataset/train/\" + img_id + '.jpg', img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_list = pd.read_parquet(\"train_image_data_3.parquet\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(len(parquet_list))):\n",
    "    img_id = parquet_list[\"image_id\"][i]\n",
    "    row = np.array(parquet_list.iloc[i][1:])\n",
    "    row = np.reshape(row, (137, 236))\n",
    "    img = np.array(row);\n",
    "    img = img.astype(np.uint8)\n",
    "    #print(img_id, img.shape)\n",
    "    cv2.imwrite(\"dataset/train/\" + img_id + '.jpg', img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['image_id', 'grapheme_root', 'vowel_diacritic', 'consonant_diacritic',\n",
       "       'grapheme'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200840/200840 [00:06<00:00, 30975.97it/s]\n"
     ]
    }
   ],
   "source": [
    "combined1 = [];\n",
    "combined2 = [];\n",
    "combined3 = [];\n",
    "\n",
    "from tqdm import tqdm\n",
    "for i in tqdm(range(len(df))):\n",
    "    img_name = df[\"image_id\"][i] + \".jpg\"\n",
    "    grapheme_root = \"grapheme_root_\" + str(df[\"grapheme_root\"][i])\n",
    "    vowel_diacritic = \"vowel_diacritic_\" + str(df[\"vowel_diacritic\"][i])\n",
    "    consonant_diacritic = \"consonant_diacritic_\" + str(df[\"consonant_diacritic\"][i])\n",
    "    combined1.append([img_name, grapheme_root]);\n",
    "    combined2.append([img_name, vowel_diacritic]);\n",
    "    combined3.append([img_name, consonant_diacritic]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(combined1, columns = ['Id', 'Label'])\n",
    "df1.to_csv(\"train_grapheme.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(combined2, columns = ['Id', 'Label'])\n",
    "df2.to_csv(\"train_vowel.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(combined3, columns = ['Id', 'Label'])\n",
    "df3.to_csv(\"train_consonent.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_list = pd.read_parquet(\"test_image_data_0.parquet\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(len(parquet_list))):\n",
    "    img_id = parquet_list[\"image_id\"][i]\n",
    "    row = np.array(parquet_list.iloc[i][1:])\n",
    "    row = np.reshape(row, (137, 236))\n",
    "    img = np.array(row);\n",
    "    img = img.astype(np.uint8)\n",
    "    #print(img_id, img.shape)\n",
    "    cv2.imwrite(\"dataset/test/\" + img_id + '.jpg', img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_list = pd.read_parquet(\"test_image_data_1.parquet\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(len(parquet_list))):\n",
    "    img_id = parquet_list[\"image_id\"][i]\n",
    "    row = np.array(parquet_list.iloc[i][1:])\n",
    "    row = np.reshape(row, (137, 236))\n",
    "    img = np.array(row);\n",
    "    img = img.astype(np.uint8)\n",
    "    #print(img_id, img.shape)\n",
    "    cv2.imwrite(\"dataset/test/\" + img_id + '.jpg', img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_list = pd.read_parquet(\"test_image_data_2.parquet\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(len(parquet_list))):\n",
    "    img_id = parquet_list[\"image_id\"][i]\n",
    "    row = np.array(parquet_list.iloc[i][1:])\n",
    "    row = np.reshape(row, (137, 236))\n",
    "    img = np.array(row);\n",
    "    img = img.astype(np.uint8)\n",
    "    #print(img_id, img.shape)\n",
    "    cv2.imwrite(\"dataset/test/\" + img_id + '.jpg', img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_list = pd.read_parquet(\"test_image_data_3.parquet\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(len(parquet_list))):\n",
    "    img_id = parquet_list[\"image_id\"][i]\n",
    "    row = np.array(parquet_list.iloc[i][1:])\n",
    "    row = np.reshape(row, (137, 236))\n",
    "    img = np.array(row);\n",
    "    img = img.astype(np.uint8)\n",
    "    #print(img_id, img.shape)\n",
    "    cv2.imwrite(\"dataset/test/\" + img_id + '.jpg', img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monk.gluon_prototype import prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mxnet Version: 1.5.1\n",
      "\n",
      "Experiment Details\n",
      "    Project: Project-Bengali-Character-Grapheme\n",
      "    Experiment: Gluon-resnet18\n",
      "    Dir: /home/ubuntu/Desktop/bengali/workspace/Project-Bengali-Character-Grapheme/Gluon-resnet18/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gtf = prototype(verbose=1);\n",
    "gtf.Prototype(\"Project-Bengali-Character-Grapheme\", \"Gluon-resnet18\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Details\n",
      "    Train path:     dataset/train/\n",
      "    Val path:       None\n",
      "    CSV train path: train_grapheme.csv\n",
      "    CSV val path:   None\n",
      "    Label Type:     single\n",
      "\n",
      "Dataset Params\n",
      "    Input Size:   224\n",
      "    Batch Size:   4\n",
      "    Data Shuffle: True\n",
      "    Processors:   8\n",
      "    Train-val split:   0.7\n",
      "    Delimiter:   ,\n",
      "\n",
      "Pre-Composed Train Transforms\n",
      "[{'RandomHorizontalFlip': {'p': 0.8}}, {'Normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]\n",
      "\n",
      "Pre-Composed Val Transforms\n",
      "[{'RandomHorizontalFlip': {'p': 0.8}}, {'Normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]\n",
      "\n",
      "Dataset Numbers\n",
      "    Num train images: 140588\n",
      "    Num val images:   60252\n",
      "    Num classes:      168\n",
      "\n",
      "Model Params\n",
      "    Model name:           resnet18_v1\n",
      "    Use Gpu:              True\n",
      "    Use pretrained:       True\n",
      "    Freeze base network:  False\n",
      "\n",
      "Model Details\n",
      "    Loading pretrained model\n",
      "    Model Loaded on device\n",
      "        Model name:                           resnet18_v1\n",
      "        Num of potentially trainable layers:  41\n",
      "        Num of actual trainable layers:       41\n",
      "\n",
      "Optimizer\n",
      "    Name:          sgd\n",
      "    Learning rate: 0.01\n",
      "    Params:        {'lr': 0.01, 'momentum': 0, 'weight_decay': 0, 'momentum_dampening_rate': 0, 'clipnorm': 0.0, 'clipvalue': 0.0}\n",
      "\n",
      "\n",
      "\n",
      "Learning rate scheduler\n",
      "    Name:   steplr\n",
      "    Params: {'step_size': 1, 'gamma': 0.98, 'last_epoch': -1}\n",
      "\n",
      "Loss\n",
      "    Name:          softmaxcrossentropy\n",
      "    Params:        {'weight': None, 'batch_axis': 0, 'axis_to_sum_over': -1, 'label_as_categories': True, 'label_smoothing': False}\n",
      "\n",
      "Training params\n",
      "    Num Epochs: 2\n",
      "\n",
      "Display params\n",
      "    Display progress:          True\n",
      "    Display progress realtime: True\n",
      "    Save Training logs:        True\n",
      "    Save Intermediate models:  True\n",
      "    Intermediate model prefix: intermediate_model_\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.virtualenvs/bengali/lib/python3.6/site-packages/monk/system/imports.py:160: UserWarning: ArgumentWarning: clipnorm and clipvalue are active only for keras in current version of Monk\n",
      "  warnings.warn(msg)\n",
      "/home/ubuntu/.virtualenvs/bengali/lib/python3.6/site-packages/monk/system/imports.py:160: UserWarning: ArgumentWarning: momentum_dampening_rate is active only for pytorch in current version of Monk\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "gtf.Default(dataset_path=\"dataset/train/\",\n",
    "            path_to_csv=\"train_grapheme.csv\",\n",
    "            model_name=\"resnet18_v1\", \n",
    "            freeze_base_network=False,\n",
    "            num_epochs=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update: Save Intermediate models - False\n",
      "\n",
      "Update: Batch size - 64\n",
      "\n",
      "Pre-Composed Train Transforms\n",
      "[{'RandomHorizontalFlip': {'p': 0.8}}, {'Normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]\n",
      "\n",
      "Pre-Composed Val Transforms\n",
      "[{'RandomHorizontalFlip': {'p': 0.8}}, {'Normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]\n",
      "\n",
      "Dataset Numbers\n",
      "    Num train images: 140588\n",
      "    Num val images:   60252\n",
      "    Num classes:      168\n",
      "\n",
      "Model Details\n",
      "    Loading pretrained model\n",
      "    Model Loaded on device\n",
      "        Model name:                           resnet18_v1\n",
      "        Num of potentially trainable layers:  41\n",
      "        Num of actual trainable layers:       41\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gtf.update_save_intermediate_models(False);\n",
    "gtf.update_batch_size(64);\n",
    "\n",
    "#Important to reload the system post updates\n",
    "gtf.Reload();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Start\n",
      "    Epoch 1/2\n",
      "    ----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af464c41875f4608b1378d1fc2599bfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2197.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e6181c8628c4b73bd85c8874c182e73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=942.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    curr_lr - 0.01\n",
      "    [Epoch 1] Train-acc: 0.613, Train-loss: 1.674 | Val-acc: 0.793716, Val-loss: 0.791, | time: 188.7 sec\n",
      "\n",
      "    Epoch 2/2\n",
      "    ----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "754d9c95a1b34814acb6f9a6fa03317b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2197.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9e0537da03e49da82218a489b98a4de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=942.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    curr_lr - 0.0098\n",
      "    [Epoch 2] Train-acc: 0.839, Train-loss: 0.600 | Val-acc: 0.855241, Val-loss: 0.535, | time: 188.7 sec\n",
      "\n",
      "    Training completed in: 6m 16s\n",
      "    Best val Acc:          0.855241\n",
      "\n",
      "Training End\n",
      "\n",
      "Training Outputs\n",
      "    Model Dir:   /home/ubuntu/Desktop/bengali/workspace/Project-Bengali-Character-Grapheme/Gluon-resnet18/output/models/\n",
      "    Log Dir:     /home/ubuntu/Desktop/bengali/workspace/Project-Bengali-Character-Grapheme/Gluon-resnet18/output/logs/\n",
      "    Final model: final\n",
      "    Best model:  best_model\n",
      "    Log 1 - Validation accuracy history log: val_acc_history.npy\n",
      "    Log 2 - Validation loss history log:     val_loss_history.npy\n",
      "    Log 3 - Training accuracy history log:   train_acc_history.npy\n",
      "    Log 4 - Training loss history log:       train_loss_history.npy\n",
      "    Log 5 - Training curve:                  train_loss_history.npy\n",
      "    Log 6 - Validation curve:                train_loss_history.npy\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train\n",
    "gtf.Train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monk.gluon_prototype import prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mxnet Version: 1.5.1\n",
      "\n",
      "Experiment Details\n",
      "    Project: Project-Bengali-Character-Vowel\n",
      "    Experiment: Gluon-resnet18\n",
      "    Dir: /home/ubuntu/Desktop/bengali/workspace/Project-Bengali-Character-Vowel/Gluon-resnet18/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gtf = prototype(verbose=1);\n",
    "gtf.Prototype(\"Project-Bengali-Character-Vowel\", \"Gluon-resnet18\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Details\n",
      "    Train path:     dataset/train/\n",
      "    Val path:       None\n",
      "    CSV train path: train_vowel.csv\n",
      "    CSV val path:   None\n",
      "    Label Type:     single\n",
      "\n",
      "Dataset Params\n",
      "    Input Size:   224\n",
      "    Batch Size:   4\n",
      "    Data Shuffle: True\n",
      "    Processors:   8\n",
      "    Train-val split:   0.7\n",
      "    Delimiter:   ,\n",
      "\n",
      "Pre-Composed Train Transforms\n",
      "[{'RandomHorizontalFlip': {'p': 0.8}}, {'Normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]\n",
      "\n",
      "Pre-Composed Val Transforms\n",
      "[{'RandomHorizontalFlip': {'p': 0.8}}, {'Normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]\n",
      "\n",
      "Dataset Numbers\n",
      "    Num train images: 140588\n",
      "    Num val images:   60252\n",
      "    Num classes:      11\n",
      "\n",
      "Model Params\n",
      "    Model name:           resnet18_v1\n",
      "    Use Gpu:              True\n",
      "    Use pretrained:       True\n",
      "    Freeze base network:  False\n",
      "\n",
      "Model Details\n",
      "    Loading pretrained model\n",
      "    Model Loaded on device\n",
      "        Model name:                           resnet18_v1\n",
      "        Num of potentially trainable layers:  41\n",
      "        Num of actual trainable layers:       41\n",
      "\n",
      "Optimizer\n",
      "    Name:          sgd\n",
      "    Learning rate: 0.01\n",
      "    Params:        {'lr': 0.01, 'momentum': 0, 'weight_decay': 0, 'momentum_dampening_rate': 0, 'clipnorm': 0.0, 'clipvalue': 0.0}\n",
      "\n",
      "\n",
      "\n",
      "Learning rate scheduler\n",
      "    Name:   steplr\n",
      "    Params: {'step_size': 1, 'gamma': 0.98, 'last_epoch': -1}\n",
      "\n",
      "Loss\n",
      "    Name:          softmaxcrossentropy\n",
      "    Params:        {'weight': None, 'batch_axis': 0, 'axis_to_sum_over': -1, 'label_as_categories': True, 'label_smoothing': False}\n",
      "\n",
      "Training params\n",
      "    Num Epochs: 2\n",
      "\n",
      "Display params\n",
      "    Display progress:          True\n",
      "    Display progress realtime: True\n",
      "    Save Training logs:        True\n",
      "    Save Intermediate models:  True\n",
      "    Intermediate model prefix: intermediate_model_\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.virtualenvs/bengali/lib/python3.6/site-packages/monk/system/imports.py:160: UserWarning: ArgumentWarning: clipnorm and clipvalue are active only for keras in current version of Monk\n",
      "  warnings.warn(msg)\n",
      "/home/ubuntu/.virtualenvs/bengali/lib/python3.6/site-packages/monk/system/imports.py:160: UserWarning: ArgumentWarning: momentum_dampening_rate is active only for pytorch in current version of Monk\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "gtf.Default(dataset_path=\"dataset/train/\",\n",
    "            path_to_csv=\"train_vowel.csv\",\n",
    "            model_name=\"resnet18_v1\", \n",
    "            freeze_base_network=False,\n",
    "            num_epochs=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update: Save Intermediate models - False\n",
      "\n",
      "Update: Batch size - 64\n",
      "\n",
      "Pre-Composed Train Transforms\n",
      "[{'RandomHorizontalFlip': {'p': 0.8}}, {'Normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]\n",
      "\n",
      "Pre-Composed Val Transforms\n",
      "[{'RandomHorizontalFlip': {'p': 0.8}}, {'Normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]\n",
      "\n",
      "Dataset Numbers\n",
      "    Num train images: 140588\n",
      "    Num val images:   60252\n",
      "    Num classes:      11\n",
      "\n",
      "Model Details\n",
      "    Loading pretrained model\n",
      "    Model Loaded on device\n",
      "        Model name:                           resnet18_v1\n",
      "        Num of potentially trainable layers:  41\n",
      "        Num of actual trainable layers:       41\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gtf.update_save_intermediate_models(False);\n",
    "gtf.update_batch_size(64);\n",
    "\n",
    "#Important to reload the system post updates\n",
    "gtf.Reload();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Start\n",
      "    Epoch 1/2\n",
      "    ----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97530fa9a85413191b95ccb98b326ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2197.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a23d1d7a594691be8cc6422b26a0e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=942.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    curr_lr - 0.01\n",
      "    [Epoch 1] Train-acc: 0.876, Train-loss: 0.375 | Val-acc: 0.928666, Val-loss: 0.219, | time: 188.7 sec\n",
      "\n",
      "    Epoch 2/2\n",
      "    ----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16793f7466df48d5a26d9ac0e3db7de2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2197.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a125469ca9e24a3dbeb734b2407491bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=942.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    curr_lr - 0.0098\n",
      "    [Epoch 2] Train-acc: 0.946, Train-loss: 0.171 | Val-acc: 0.946923, Val-loss: 0.166, | time: 188.9 sec\n",
      "\n",
      "    Training completed in: 6m 16s\n",
      "    Best val Acc:          0.946923\n",
      "\n",
      "Training End\n",
      "\n",
      "Training Outputs\n",
      "    Model Dir:   /home/ubuntu/Desktop/bengali/workspace/Project-Bengali-Character-Vowel/Gluon-resnet18/output/models/\n",
      "    Log Dir:     /home/ubuntu/Desktop/bengali/workspace/Project-Bengali-Character-Vowel/Gluon-resnet18/output/logs/\n",
      "    Final model: final\n",
      "    Best model:  best_model\n",
      "    Log 1 - Validation accuracy history log: val_acc_history.npy\n",
      "    Log 2 - Validation loss history log:     val_loss_history.npy\n",
      "    Log 3 - Training accuracy history log:   train_acc_history.npy\n",
      "    Log 4 - Training loss history log:       train_loss_history.npy\n",
      "    Log 5 - Training curve:                  train_loss_history.npy\n",
      "    Log 6 - Validation curve:                train_loss_history.npy\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train\n",
    "gtf.Train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monk.gluon_prototype import prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mxnet Version: 1.5.1\n",
      "\n",
      "Experiment Details\n",
      "    Project: Project-Bengali-Character-Consonent\n",
      "    Experiment: Gluon-resnet18\n",
      "    Dir: /home/ubuntu/Desktop/bengali/workspace/Project-Bengali-Character-Consonent/Gluon-resnet18/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gtf = prototype(verbose=1);\n",
    "gtf.Prototype(\"Project-Bengali-Character-Consonent\", \"Gluon-resnet18\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Details\n",
      "    Train path:     dataset/train/\n",
      "    Val path:       None\n",
      "    CSV train path: train_consonent.csv\n",
      "    CSV val path:   None\n",
      "    Label Type:     single\n",
      "\n",
      "Dataset Params\n",
      "    Input Size:   224\n",
      "    Batch Size:   4\n",
      "    Data Shuffle: True\n",
      "    Processors:   8\n",
      "    Train-val split:   0.7\n",
      "    Delimiter:   ,\n",
      "\n",
      "Pre-Composed Train Transforms\n",
      "[{'RandomHorizontalFlip': {'p': 0.8}}, {'Normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]\n",
      "\n",
      "Pre-Composed Val Transforms\n",
      "[{'RandomHorizontalFlip': {'p': 0.8}}, {'Normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]\n",
      "\n",
      "Dataset Numbers\n",
      "    Num train images: 140588\n",
      "    Num val images:   60252\n",
      "    Num classes:      7\n",
      "\n",
      "Model Params\n",
      "    Model name:           resnet18_v1\n",
      "    Use Gpu:              True\n",
      "    Use pretrained:       True\n",
      "    Freeze base network:  False\n",
      "\n",
      "Model Details\n",
      "    Loading pretrained model\n",
      "    Model Loaded on device\n",
      "        Model name:                           resnet18_v1\n",
      "        Num of potentially trainable layers:  41\n",
      "        Num of actual trainable layers:       41\n",
      "\n",
      "Optimizer\n",
      "    Name:          sgd\n",
      "    Learning rate: 0.01\n",
      "    Params:        {'lr': 0.01, 'momentum': 0, 'weight_decay': 0, 'momentum_dampening_rate': 0, 'clipnorm': 0.0, 'clipvalue': 0.0}\n",
      "\n",
      "\n",
      "\n",
      "Learning rate scheduler\n",
      "    Name:   steplr\n",
      "    Params: {'step_size': 1, 'gamma': 0.98, 'last_epoch': -1}\n",
      "\n",
      "Loss\n",
      "    Name:          softmaxcrossentropy\n",
      "    Params:        {'weight': None, 'batch_axis': 0, 'axis_to_sum_over': -1, 'label_as_categories': True, 'label_smoothing': False}\n",
      "\n",
      "Training params\n",
      "    Num Epochs: 2\n",
      "\n",
      "Display params\n",
      "    Display progress:          True\n",
      "    Display progress realtime: True\n",
      "    Save Training logs:        True\n",
      "    Save Intermediate models:  True\n",
      "    Intermediate model prefix: intermediate_model_\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.virtualenvs/bengali/lib/python3.6/site-packages/monk/system/imports.py:160: UserWarning: ArgumentWarning: clipnorm and clipvalue are active only for keras in current version of Monk\n",
      "  warnings.warn(msg)\n",
      "/home/ubuntu/.virtualenvs/bengali/lib/python3.6/site-packages/monk/system/imports.py:160: UserWarning: ArgumentWarning: momentum_dampening_rate is active only for pytorch in current version of Monk\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "gtf.Default(dataset_path=\"dataset/train/\",\n",
    "            path_to_csv=\"train_consonent.csv\",\n",
    "            model_name=\"resnet18_v1\", \n",
    "            freeze_base_network=False,\n",
    "            num_epochs=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update: Save Intermediate models - False\n",
      "\n",
      "Update: Batch size - 64\n",
      "\n",
      "Pre-Composed Train Transforms\n",
      "[{'RandomHorizontalFlip': {'p': 0.8}}, {'Normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]\n",
      "\n",
      "Pre-Composed Val Transforms\n",
      "[{'RandomHorizontalFlip': {'p': 0.8}}, {'Normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]\n",
      "\n",
      "Dataset Numbers\n",
      "    Num train images: 140588\n",
      "    Num val images:   60252\n",
      "    Num classes:      7\n",
      "\n",
      "Model Details\n",
      "    Loading pretrained model\n",
      "    Model Loaded on device\n",
      "        Model name:                           resnet18_v1\n",
      "        Num of potentially trainable layers:  41\n",
      "        Num of actual trainable layers:       41\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gtf.update_save_intermediate_models(False);\n",
    "gtf.update_batch_size(64);\n",
    "\n",
    "#Important to reload the system post updates\n",
    "gtf.Reload();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Start\n",
      "    Epoch 1/2\n",
      "    ----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccd5dc2a173e4608881e61b607a21afe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2197.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ac1ff9163a47dcb6c5d2e97686525b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=942.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    curr_lr - 0.01\n",
      "    [Epoch 1] Train-acc: 0.890, Train-loss: 0.324 | Val-acc: 0.928368, Val-loss: 0.214, | time: 188.6 sec\n",
      "\n",
      "    Epoch 2/2\n",
      "    ----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d384887c3d44e4a499385516e07ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2197.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15c6f0faaec54b458ef10bde91a4ef1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=942.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    curr_lr - 0.0098\n",
      "    [Epoch 2] Train-acc: 0.944, Train-loss: 0.169 | Val-acc: 0.945114, Val-loss: 0.171, | time: 189.0 sec\n",
      "\n",
      "    Training completed in: 6m 17s\n",
      "    Best val Acc:          0.945114\n",
      "\n",
      "Training End\n",
      "\n",
      "Training Outputs\n",
      "    Model Dir:   /home/ubuntu/Desktop/bengali/workspace/Project-Bengali-Character-Consonent/Gluon-resnet18/output/models/\n",
      "    Log Dir:     /home/ubuntu/Desktop/bengali/workspace/Project-Bengali-Character-Consonent/Gluon-resnet18/output/logs/\n",
      "    Final model: final\n",
      "    Best model:  best_model\n",
      "    Log 1 - Validation accuracy history log: val_acc_history.npy\n",
      "    Log 2 - Validation loss history log:     val_loss_history.npy\n",
      "    Log 3 - Training accuracy history log:   train_acc_history.npy\n",
      "    Log 4 - Training loss history log:       train_loss_history.npy\n",
      "    Log 5 - Training curve:                  train_loss_history.npy\n",
      "    Log 6 - Validation curve:                train_loss_history.npy\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train\n",
    "gtf.Train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
