{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Tessellate-Imaging/monk_v1/blob/master/study_roadmaps/4_image_classification_zoo/Classifier%20-%20Yoga%20Pose%20Type%20Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "\n",
    "\n",
    "## Install Monk\n",
    "\n",
    "\n",
    "## Using pretrained model for classifying yoga posture types \n",
    "\n",
    "\n",
    "## Training a classifier from scratch\n",
    "\n",
    "\n",
    "## Hyper-parameter tuning using Monk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "# Install Monk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using pip (Recommended)\n",
    "\n",
    "  - colab (gpu) \n",
    "      - All bakcends: `pip install -U monk-colab`\n",
    "      \n",
    "\n",
    "  - kaggle (gpu) \n",
    "      - All backends: `pip install -U monk-kaggle`\n",
    "      \n",
    "\n",
    "  - cuda 10.2\t\n",
    "      - All backends: `pip install -U monk-cuda102`\n",
    "      - Gluon bakcned: `pip install -U monk-gluon-cuda102`\n",
    "\t  - Pytorch backend: `pip install -U monk-pytorch-cuda102`\n",
    "      - Keras backend: `pip install -U monk-keras-cuda102`\n",
    "      \n",
    "\n",
    "  - cuda 10.1\t\n",
    "      - All backend: `pip install -U monk-cuda101`\n",
    "\t  - Gluon bakcned: `pip install -U monk-gluon-cuda101`\n",
    "\t  - Pytorch backend: `pip install -U monk-pytorch-cuda101`\n",
    "\t  - Keras backend: `pip install -U monk-keras-cuda101`\n",
    "      \n",
    "\n",
    "  - cuda 10.0\t\n",
    "      - All backend: `pip install -U monk-cuda100`\n",
    "\t  - Gluon bakcned: `pip install -U monk-gluon-cuda100`\n",
    "\t  - Pytorch backend: `pip install -U monk-pytorch-cuda100`\n",
    "\t  - Keras backend: `pip install -U monk-keras-cuda100`\n",
    "      \n",
    "\n",
    "  - cuda 9.2\t\n",
    "      - All backend: `pip install -U monk-cuda92`\n",
    "\t  - Gluon bakcned: `pip install -U monk-gluon-cuda92`\n",
    "\t  - Pytorch backend: `pip install -U monk-pytorch-cuda92`\n",
    "\t  - Keras backend: `pip install -U monk-keras-cuda92`\n",
    "      \n",
    "\n",
    "  - cuda 9.0\t\n",
    "      - All backend: `pip install -U monk-cuda90`\n",
    "\t  - Gluon bakcned: `pip install -U monk-gluon-cuda90`\n",
    "\t  - Pytorch backend: `pip install -U monk-pytorch-cuda90`\n",
    "\t  - Keras backend: `pip install -U monk-keras-cuda90`\n",
    "      \n",
    "\n",
    "  - cpu \t\t\n",
    "      - All backend: `pip install -U monk-cpu`\n",
    "\t  - Gluon bakcned: `pip install -U monk-gluon-cpu`\n",
    "\t  - Pytorch backend: `pip install -U monk-pytorch-cpu`\n",
    "\t  - Keras backend: `pip install -U monk-keras-cpu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Monk Manually (Not recommended)\n",
    " \n",
    "### Step 1: Clone the library\n",
    " - git clone https://github.com/Tessellate-Imaging/monk_v1.git\n",
    " \n",
    " \n",
    " \n",
    " \n",
    "### Step 2: Install requirements \n",
    " - Linux\n",
    "     - Cuda 9.0\n",
    "         - `cd monk_v1/installation/Linux && pip install -r requirements_cu90.txt`\n",
    "     - Cuda 9.2\n",
    "         - `cd monk_v1/installation/Linux && pip install -r requirements_cu92.txt`\n",
    "     - Cuda 10.0\n",
    "         - `cd monk_v1/installation/Linux && pip install -r requirements_cu100.txt`\n",
    "     - Cuda 10.1\n",
    "         - `cd monk_v1/installation/Linux && pip install -r requirements_cu101.txt`\n",
    "     - Cuda 10.2\n",
    "         - `cd monk_v1/installation/Linux && pip install -r requirements_cu102.txt`\n",
    "     - CPU (Non gpu system)\n",
    "         - `cd monk_v1/installation/Linux && pip install -r requirements_cpu.txt`\n",
    " \n",
    " \n",
    "  - Windows\n",
    "     - Cuda 9.0 (Experimental support)\n",
    "         - `cd monk_v1/installation/Windows && pip install -r requirements_cu90.txt`\n",
    "     - Cuda 9.2 (Experimental support)\n",
    "         - `cd monk_v1/installation/Windows && pip install -r requirements_cu92.txt`\n",
    "     - Cuda 10.0 (Experimental support)\n",
    "         - `cd monk_v1/installation/Windows && pip install -r requirements_cu100.txt`\n",
    "     - Cuda 10.1 (Experimental support)\n",
    "         - `cd monk_v1/installation/Windows && pip install -r requirements_cu101.txt`\n",
    "     - Cuda 10.2 (Experimental support)\n",
    "         - `cd monk_v1/installation/Windows && pip install -r requirements_cu102.txt`\n",
    "     - CPU (Non gpu system)\n",
    "         - `cd monk_v1/installation/Windows && pip install -r requirements_cpu.txt`\n",
    "         \n",
    "         \n",
    "  - Mac\n",
    "     - CPU (Non gpu system)\n",
    "         - `cd monk_v1/installation/Mac && pip install -r requirements_cpu.txt`\n",
    "         \n",
    "         \n",
    "  - Misc\n",
    "      - Colab (GPU)\n",
    "          - `cd monk_v1/installation/Misc && pip install -r requirements_colab.txt`\n",
    "      - Kaggle (GPU)\n",
    "          - `cd monk_v1/installation/Misc && pip install -r requirements_kaggle.txt`\n",
    " \n",
    " \n",
    " \n",
    "### Step 3: Add to system path (Required for every terminal or kernel run)\n",
    " - `import sys`\n",
    " - `sys.path.append(\"monk_v1/\");`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Download\n",
    "    - Credits: https://sites.google.com/view/yoga-82/home\n",
    "   \n",
    "    - Fill the form to get access to the downset\n",
    "    - Once downloaded, unzip it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo rm  Yoga-82/yoga_dataset_links/desktop.ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = os.listdir(\"Yoga-82/yoga_dataset_links\");\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "for i in tqdm(range(len(file_list))):\n",
    "    f = open(\"Yoga-82/yoga_dataset_links/\" + file_list[i], 'r');\n",
    "    lines = f.readlines();\n",
    "    f.close();\n",
    "    \n",
    "    for j in tqdm(range(len(lines))):\n",
    "        #print(lines[j])\n",
    "        splits = lines[j][:len(lines[j])-1].split(\",\")\n",
    "        img_path = splits[0];\n",
    "        link = splits[1];\n",
    "        \n",
    "        folder_name, img_name = img_path.split(\"/\");\n",
    "        if(j == 0):\n",
    "            if(not os.path.isdir(\"Images/\" + folder_name)):\n",
    "                os.mkdir(\"Images/\" + folder_name)\n",
    "        os.system(\"wget -O \" + \"Images/\" + folder_name + \"/\" + img_name + \" \" + link)\n",
    "        try:\n",
    "            img = Image.open(\"Images/\" + folder_name + \"/\" + img_name)\n",
    "            img.verify()     # to veify if its an img\n",
    "            img.close()     #to close img and free memory space\n",
    "        except (IOError, SyntaxError) as e:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split trainging and testing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"Yoga-82/yoga_test.txt\");\n",
    "lines = f.readlines();\n",
    "f.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "for i in tqdm(range(len(lines))):\n",
    "    folder_name, img_name = lines[i].split(\",\")[0].split(\"/\");\n",
    "    if(not os.path.isdir(\"Test/\" + folder_name)):\n",
    "        os.mkdir(\"Test/\" + folder_name);\n",
    "    os.system(\"mv \" + \"Images/\" + folder_name + \"/\" + img_name + \" Test/\" + folder_name + \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Used trained classifier for demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using pytorch backend \n",
    "\n",
    "# When installed using pip\n",
    "from monk.pytorch_prototype import prototype\n",
    "\n",
    "\n",
    "# When installed manually (Uncomment the following)\n",
    "#import os\n",
    "#import sys\n",
    "#sys.path.append(\"monk_v1/\");\n",
    "#sys.path.append(\"monk_v1/monk/\");\n",
    "#from monk.pytorch_prototype import prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1KL0wzmh8xAwhmBZf8Uee2-LcHgd43zr5' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1KL0wzmh8xAwhmBZf8Uee2-LcHgd43zr5\" -O cls_yoga82_trained.zip && rm -rf /tmp/cookies.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! unzip -qq cls_yoga82_trained.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls workspace/Project-Yoga-82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load project in inference mode\n",
    "\n",
    "gtf = prototype(verbose=1);\n",
    "gtf.Prototype(\"Project-Yoga-82\", \"Pytorch-densenet201\", eval_infer=True);\n",
    "\n",
    "#Other trained models - uncomment \n",
    "#gtf.Prototype(\"Project-Yoga-82\", \"Pytorch-densenet169\", eval_infer=True);\n",
    "#gtf.Prototype(\"Project-Yoga-82\", \"Pytorch-densenet161\", eval_infer=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = \"Test/Akarna_Dhanurasana/1.jpg\"\n",
    "img_resized = \"Test/Akarna_Dhanurasana/1_resized.jpg\"\n",
    "predictions = gtf.Infer(img_name=img_name);\n",
    "from IPython.display import Image\n",
    "img = cv2.imread(img_name, 1);\n",
    "img = cv2.resize(img, (640, 480))\n",
    "cv2.imwrite(img_resized, img)\n",
    "Image(filename=img_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = \"Test/Boat_Pose_or_Paripurna_Navasana_/248.jpg\"\n",
    "img_resized = \"Test/Boat_Pose_or_Paripurna_Navasana_/248_resized.jpg\"\n",
    "predictions = gtf.Infer(img_name=img_name);\n",
    "from IPython.display import Image\n",
    "img = cv2.imread(img_name, 1);\n",
    "img = cv2.resize(img, (640, 480))\n",
    "cv2.imwrite(img_resized, img)\n",
    "Image(filename=img_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = \"Test/Corpse_Pose_or_Savasana_/231.jpg\"\n",
    "img_resized = \"Test/Corpse_Pose_or_Savasana_/231_resized.jpg\"\n",
    "predictions = gtf.Infer(img_name=img_name);\n",
    "from IPython.display import Image\n",
    "img = cv2.imread(img_name, 1);\n",
    "img = cv2.resize(img, (640, 480))\n",
    "cv2.imwrite(img_resized, img)\n",
    "Image(filename=img_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = \"Test/Dolphin_Pose_or_Ardha_Pincha_Mayurasana_/340.jpg\"\n",
    "img_resized = \"Test/Dolphin_Pose_or_Ardha_Pincha_Mayurasana_/340_resized.jpg\"\n",
    "predictions = gtf.Infer(img_name=img_name);\n",
    "from IPython.display import Image\n",
    "img = cv2.imread(img_name, 1);\n",
    "img = cv2.resize(img, (640, 480))\n",
    "cv2.imwrite(img_resized, img)\n",
    "Image(filename=img_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For mxnet-gluon backend \n",
    "#from monk.gluon_prototype import prototype\n",
    "\n",
    "# For pytorch backend\n",
    "from monk.pytorch_prototype import prototype\n",
    "\n",
    "# For Keras backend\n",
    "#from monk.keras_prototype import prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Project and Experiment\n",
    "\n",
    "gtf = prototype(verbose=1);\n",
    "gtf.Prototype(\"Project-Yoga-82\", \"Pytorch-resnet18\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.Default(dataset_path=[\"Images\", \"Test\"],\n",
    "            model_name=\"resnet18\", \n",
    "            freeze_base_network=True,\n",
    "            num_epochs=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start Training\n",
    "gtf.Train();\n",
    "\n",
    "#Read the training summary generated once you run the cell and training is completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation set accuracy was - 0.532\n",
    "\n",
    "    Note: You may get a different result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis Project Name\n",
    "analysis_name = \"analyse_models\";\n",
    "\n",
    "# Models to analyse\n",
    "# First element in the list- Model Name\n",
    "# Second element in the list - Boolean value to freeze base network or not\n",
    "# Third element in the list - Boolean value to use pretrained model as the starting point or not\n",
    "models = [[\"resnet18\", True, True], [\"resnet34\", False, True], [\"resnet50\", False, True],\n",
    "         [\"resnet50\", False, False], [\"resnet101\", False, True]];  \n",
    "\n",
    "# Num epochs for each experiment to run\t\n",
    "epochs=10;\n",
    "\n",
    "# Percentage of original dataset to take in for experimentation\n",
    "percent_data=10;\n",
    "\n",
    "# \"keep_all\" - Keep all the sub experiments created\n",
    "# \"keep_non\" - Delete all sub experiments created\n",
    "analysis = gtf.Analyse_Models(analysis_name, models, percent_data, num_epochs=epochs, state=\"keep_none\"); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As per results set the apropriate model\n",
    "gtf.update_model_name(\"resnet50\");\n",
    "gtf.update_freeze_base_network(False);\n",
    "gtf.update_use_pretrained(True);\n",
    "\n",
    "#Very Important to reload experiment to make the changes\n",
    "gtf.Reload();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_name = \"analyse_input_sizes\";\n",
    "\n",
    "# Input sizes to explore\t\n",
    "input_sizes = [128, 256, 512];\n",
    "\n",
    "# Num epochs for each experiment to run\t\n",
    "epochs=10;\n",
    "\n",
    "# Percentage of original dataset to take in for experimentation\n",
    "percent_data=10;\n",
    "\n",
    "# \"keep_all\" - Keep all the sub experiments created\n",
    "# \"keep_non\" - Delete all sub experiments created\t\n",
    "analysis = gtf.Analyse_Input_Sizes(analysis_name, input_sizes, \n",
    "                                   percent_data, num_epochs=epochs, state=\"keep_none\"); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As per results set the apropriate input size\n",
    "gtf.update_input_size(512);\n",
    "\n",
    "#Very Important to reload experiment to make the changes\n",
    "gtf.Reload();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis Project Name\n",
    "analysis_name = \"analyse_batch_sizes\";\n",
    "\n",
    "# Batch sizes to explore\n",
    "batch_sizes = [4, 8, 16, 32];\n",
    "\n",
    "# Num epochs for each experiment to run\t\n",
    "epochs = 5;\n",
    "\n",
    "# Percentage of original dataset to take in for experimentation\n",
    "percent_data = 20;\n",
    "\n",
    "# \"keep_all\" - Keep all the sub experiments created\n",
    "# \"keep_non\" - Delete all sub experiments created\t\n",
    "analysis = gtf.Analyse_Batch_Sizes(analysis_name, batch_sizes, \n",
    "                                   percent_data, num_epochs=epochs, state=\"keep_none\"); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As per results set the apropriate batch size\n",
    "gtf.update_batch_size(32);\n",
    "\n",
    "#Very Important to reload experiment to make the changes\n",
    "gtf.Reload();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis Project Name\n",
    "analysis_name = \"analyse_optimizers_with_lr\";\n",
    "\n",
    "# Optimizers to explore\n",
    "optimizers_lrs = [[\"sgd\", 0.001], \n",
    "                  [\"sgd\", 0.01], \n",
    "                  [\"adam\", 0.001], \n",
    "                  [\"adam\", 0.01], \n",
    "                  [\"adagrad\", 0.001], \n",
    "                  [\"adagrad\", 0.01], \n",
    "                  [\"adadelta\", 0.001],\n",
    "                  [\"adagrad\", 0.01]];   #Model name, learning rate\n",
    "\n",
    "# Num epochs for each experiment to run\t\n",
    "epochs = 10;\n",
    "\n",
    "# Percentage of original dataset to take in for experimentation\n",
    "percent_data = 10;\n",
    "\n",
    "# \"keep_all\" - Keep all the sub experiments created\n",
    "# \"keep_non\" - Delete all sub experiments created\n",
    "analysis = gtf.Analyse_Optimizers_With_LR(analysis_name, \n",
    "                                          optimizers_lrs, percent_data, num_epochs=epochs, state=\"keep_none\"); \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As per results set the appropriate \n",
    "gtf.optimizer_sgd(0.001);\n",
    "\n",
    "#Very Important to reload experiment to make the changes\n",
    "gtf.Reload();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptf.Train();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New validation accuracy - 0.78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer on a an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For mxnet-gluon backend \n",
    "#from monk.gluon_prototype import prototype\n",
    "\n",
    "# For pytorch backend\n",
    "from monk.pytorch_prototype import prototype\n",
    "\n",
    "# For Keras backend\n",
    "#from monk.keras_prototype import prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Project and Experiment\n",
    "\n",
    "gtf = prototype(verbose=1);\n",
    "gtf.Prototype(\"Project-Yoga-82\", \"Pytorch-resnet50\", eval_infer=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = \"Test/Akarna_Dhanurasana/1.jpg\"\n",
    "predictions = gtf.Infer(img_name=img_name);\n",
    "from IPython.display import Image\n",
    "Image(filename=img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
